<!DOCTYPE html>
<html lang="en">
  <head>
    <!--
                                      _
        /\     _             _   _   | |             __    __
       /  \   | |      /\   | \ | |  | |       /\   |  \  /  |
      /    \  | |     /  \  |  \| |  | |      /  \  | |\\//| |
     / ____ \ | |__  / __ \ | |\  |  | |___  / __ \ | | \/ | |
    /_/    \_\|____|/_/  \_\|_| \_|  |_____|/_/  \_\|_|    |_|
                          _   _
     _  _    _     _  _  | | | |   __     ____
    | |/ \  | |_  | |/_| | | | |  /  \   /    \
    | |   | |  _| |  /   | | | | | || | |  ||  |
    | |   | | |_  | |    | | | | | || | |  ||  |
    |_|   | |___| |_|    |_| |_|  \__/   \____/|
                                               |
                                          ____/
    -->
    <title>ntrllog | Advanced Artificial Intelligence</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet">
    <link rel="shortcut icon" type="image/png" href="../pictures/favicon.ico"/>
    <link href="../css/content.css" rel="stylesheet">
  </head>
  <body>
    <div class="dropdown ln-fixed-right">
      <button class="btn btn-secondary dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">ToC</button>
      <ul class="dropdown-menu">
        <li><a class="dropdown-item" href="#whatisit">What's the Problem?</a></li>
        <li><a class="dropdown-item" href="#nqueens">The `n`-Queens Problem</a></li>
        <li><a class="dropdown-item" href="#evolutionarycomputing">Evolutionary Computing</a></li>
        <li><a class="dropdown-item" href="#variationoperators">Variation Operators</a></li>
        <li><a class="dropdown-item" href="#selectionoperators">Selection Operators</a></li>
        <li><a class="dropdown-item" href="#eavariants">Evolutionary Algorithm Variants</a></li>
        <li><a class="dropdown-item" href="#parametertuning">Parameters and Parameter Tuning</a></li>
        <li><a class="dropdown-item" href="#multiobjective">Multiobjective Evolutionary Algorithms</a></li>
        <li><a class="dropdown-item" href="#llm">LLMs</a></li>
      </ul>
    </div>
    <div class="container ln-line-height">
      <a href="projects.html"><i class="fas fa-long-arrow-alt-left fa-2x"></i></a>
      <h1>Advanced Artificial Intelligence</h1>
      <hr>
      <p>Shortcut to this page: <a href="ai2.html">ntrllog.netlify.app/ai2</a></p>
      <p>Notes provided by Professor Armando Beltran (CSULA), <a href="http://www.evolutionarycomputation.org/" target="_blank">Introduction to Evolutionary Computing</a>, and <a href="https://sebastianraschka.com/books/" target="_blank">Build a Large Language Model (From Scratch)</a></p>
      <p>This is an extension of the <a href="ai.html" target="_blank">artificial intelligence</a> and <a href="ml.html" target="_blank">machine learning</a> resources. Well, we’ll see where this goes — I’m writing this as the class goes.</p>
      <h2 id="whatisit">What's the Problem?</h2>
      <p>As computer scientists, we aim to develop and use AI to solve problems optimally. But before we look at how AI works, we should start with understanding what types of problems exist and how to define them.</p>
      <h3>Black Box Model</h3>
      <p>Some problems can be reduced to a "black box" model. The "black box" model has `3` components: an input, a model (algorithm or function), and an output. If one of the three components is unknown, then that is a problem we can define and solve.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/ai2/black_box_model.png">
      </div>
      <h4>Optimization</h4>
      <p>If the input is unknown, then we have an optimization problem. As the name implies, optimization problems seek to maximize or minimize a result.</p>
      <p>For example, we’re traveling and we want to visit a bunch of destinations while minimizing time traveled, i.e., we want an efficient route so that we don’t waste time. The model is a function that calculates the time it takes to go from one destination to another. The output is a number representing the total time traveled (we want to minimize this). The input — which is what we want to solve for — is a route.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/ai2/optimization_1.png">
      </div>
      <p>Another example is the `8`-queens problem. We want to place `8` queens such that no queens are attacking each other. The model is a function that calculates how many queens are attacking each other. The output is the number of queens attacking each other (we want to maximize this). The input — which is what we want to solve for — is a configuration of `8` queens.</p>
      <h5>Objective Function</h5>
      <p>As mentioned earlier, optimization problems aim to maximize or minimize a result. That result is calculated by a function, namely an objective function. An objective function is a math expression that quantifies the quality of a potential solution to an optimization problem. (The quality of a solution is how well it solves the problem.)</p>
      <p>In other words, an objective function assigns a numerical value to an input, and that numerical value is a measure of how good that input is as a solution to the problem.</p>
      <h4>Modeling</h4>
      <p>If the model is unknown, then we have a modeling problem. In these types of problems, we have the inputs and outputs, and we want to know what type of model fits the data.</p>
      <p>Let’s say we have these inputs and outputs:</p>
      <div class="ln-center">
        <table class="table">
          <tr>
            <th>x</th>
            <th>y</th>
          </tr>
          <tr>
            <td>`1`</td>
            <td>`2`</td>
          </tr>
          <tr>
            <td>`2`</td>
            <td>`4`</td>
          </tr>
          <tr>
            <td>`3`</td>
            <td>`6`</td>
          </tr>
          <tr>
            <td>`4`</td>
            <td>`8`</td>
          </tr>
          <tr>
            <td>`5`</td>
            <td>`10`</td>
          </tr>
        </table>
      </div>
      <p>In this case, we can figure out that the model is the function `y = 2x`.</p>
      <p>A real-world example is voice recognition. We have the inputs (a set of spoken text) and the outputs (a set of written text), and we want to build a model that can match the spoken text to the written text.</p>
      <div class="ln-box">
        <p>Modeling problems can be transformed into optimization problems by picking a model that works and then optimizing that model.</p>
      </div>
      <h4>Simulation</h4>
      <p>If the output is unknown, then we have a simulation problem. These types of problems are like exploring "what if" scenarios.</p>
      <p>For example, predicting the weather is a simulation problem. The inputs are data points for things like humidity and temperature. The model is a function that takes in those data points and returns a weather. "What if it is humid and hot?"</p>
      <h3>The Search for Answers</h3>
      <p>Honestly, simulation problems don’t really sound like "problems" at all. All we need to do is run the model on the inputs and get our answer.</p>
      <p>On the other hand, for optimization and modeling problems, we have to search for something. For optimization problems, we have to <em>find</em> the input that gives us the desired output. For modeling problems, we have to <em>find</em> the model that gives us the desired output for the given inputs.</p>
      <p>Formally, there is a search space, which is a set of objects of interest, including the desired solution. It can typically be represented as a search tree.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/ai2/search_space.png">
      </div>
      <p>For the time-efficient traveling problem, the search space is a bunch of possible routes and we have to find one that is the most time-efficient. For the voice-recognition problem, the search space is a bunch of models and we have to find one that is the most accurate.</p>
      <p>Typically, the search space for any problem will be very large, so we need an efficient way to explore the search space for the desired solution. A problem solver does this for us. A good problem solver goes through the search space and finds the optimal path through the search tree to the desired solution.</p>
      <h3>NP Problems</h3>
      <p>Some problems are inherently hard for computers to solve. This could be because it takes a really long time and/or a lot of memory is needed to find the solution. The difficulty of a problem can be classified into four categories:</p>
      <ul>
        <li>Class P: problems that can be solved in polynomial time</li>
        <li>Class NP: problems that can be verified in polynomial time
          <ul>
            <li>the "N" stands for "nondeterministic"</li>
          </ul>
        </li>
        <li>Class NP-complete: a problem `p` is NP-complete if every other NP problem can be transformed/reduced to `p`
          <ul>
            <li>if it turns out that an NP-complete problem can be solved in polynomial time, then all NP problems can be solved in polynomial time</li>
          </ul>
        </li>
        <li>Class NP-hard: problems that are at least as hard as NP-complete problems, but the solution may not be verfiable in polynomial time</li>
      </ul>
      <div class="ln-box">
        <p>These classifications (except for NP-hard) apply to decision problems: problems that have a "yes" or "no" answer. For example, "Is `A rarr B rarr C rarr D` the optimal route?"</p>
      </div>
      <h2 id="nqueens">The `n`-Queens Problem</h2>
      <p>The `n`-queens problem is an optimization problem that involves placing `n` queens on a chessboard such that none of the queens are attacking each other. For example, for `n=4`:</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-smaller" src="../pictures/ai2/4_queens.png">
      </div>
      <p>To formalize things, we can frame the problem statement as, "Given `n` queens, find a configuration for the queens on an `n xx n` chessboard that maximizes the number of pairs of non-attacking queens."</p>
      <p>If we label the top-left corner as row `1`, column `1`, then we can represent a board configuration using coordinates. So for the example above, we have</p>
      <div class="ln-center">
        <p>`Q = {(2,1), (4,2), (1,3), (3,4)}`</p>
      </div>
      <p>The objective function `f` can be represented as</p>
      <div class="ln-center">
        <p>`max_Q f(Q) = (n(n-1))/2-A(Q)`</p>
      </div>
      <p>where `A(Q)` is the number of pairs of attacking queens for a board configuration `Q`.</p>
      <div class="ln-box">
        <p>`A(Q)` is the number of <em>pairs</em> of attacking queens (as opposed to the number of queens being attacked). In this example, there are `4` pairs of attacking queens.</p>
        <div class="ln-center">
          <img class="img-fluid ln-image-smaller" src="../pictures/ai2/4_queens_2.png">
        </div>
      </div>
      <div class="ln-box">
        <p>`(n(n-1))/2` is the number of total possible pairs of queens. If we subtract the number of pairs of attacking queens from that expression, we get the number of pairs of non-attacking queens (which is what we're trying to maximize).</p>
      </div>
      <h3>Free Optimization Approach</h3>
      <p>Now that we have formally defined the problem, we can start to look at how hard this problem is to solve. For optimization problems, the difficulty depends on the size of the search space. The more inputs there are to search through, the harder the problem is.</p>
      <p>So how many possible board configurations are there? We'll first consider the `n=4` case.</p>
      <p>For the first queen, there are `16` spaces for where it can be placed. For the second queen, there are `15` spaces. For the third queen, there are `14` spaces. For the last queen, there are `13` spaces. So there are a total of `16*15*14*13=43,680` possible board configurations.</p>
      <div class="ln-box">
        <p>In general, there are</p>
        <div class="ln-center">
          <p>`(n^2!)/((n^2-n)!)`</p>
        </div>
        <p>possible board configurations.</p>
      </div>
      <p>For a standard `8xx8` chessboard, there are `1.78 xx 10^(14)` possible board configurations. Yeah, that's a lot to search through.</p>
      <h3>Constrained Optimization Approach: Row Constraint</h3>
      <p>Is it possible to make the search space smaller? Well, notice that if more than `1` queen is on the same row, then they're automatically attacking each other.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-smaller" src="../pictures/ai2/4_queens_3.png">
      </div>
      <p>So any board configurations where there is more than `1` queen in the same row can be removed from the search space. We can achieve this by reframing the problem statement as, "Given `n` queens, find a configuration for the queens on an `n xx n` chessboard such that <strong>every row contains exactly one queen</strong> while maximizing the number of pairs of non-attacking queens." We're introducing a constraint on the original problem.</p>
      <p>Also, instead of using coordinates to represent a board configuration, we can use a vector representation.</p>
      <div class="ln-box">
        <div class="ln-center">
          <p>`Q = [Q_1, Q_2, ..., Q_n]^T`</p>
        </div>
        <p>where index `i` represents the row number and `Q_i` is the column number.</p>
      </div>
      <div class="ln-center">
        <img class="img-fluid ln-image-smaller" src="../pictures/ai2/4_queens.png">
        <p>`Q = [3, 1, 4, 2]^T`</p>
      </div>
      <p>By using a vector, we force all possible board configurations to have exactly `1` queen in every row.</p>
      <p>Let's see how much the search space has been reduced by with this new constraint. Again, we'll first consider the `n=4` case.</p>
      <p>The first queen can only be placed in the first row, and in the first row, there are only `4` spaces for it. The second queen can only be placed in the second row, and in the second row, there are only `4` spaces for it. The third queen can only be placed in the third row, and in the third row, there are only `4` spaces for it. The last queen can only be placed in the fourth row, and in the fourth row, there are only `4` spaces for it. So there are a total of `4*4*4*4=256` possible board configurations.</p>
      <div class="ln-box">
        <p>In general, there are</p>
        <div class="ln-center">
          <p>`n^n`</p>
        </div>
        <p>possible board configurations.</p>
      </div>
      <p>So we went from `43,680` to `256`, which is pretty good. For the `n=8` case, there are `16,777,216` possible board configurations, which is much less than `1.78 xx 10^(14)`, but still a lot.</p>
      <h3>Constrained Optimization Approach: Row and Column Constraint</h3>
      <p>We can apply the same row-constraint reasoning to the columns as well: if there is more than `1` queen on the same column, then they're automatically attacking each other.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-smaller" src="../pictures/ai2/4_queens_4.png">
      </div>
      <p>So any board configurations where there is more than `1` queen in the same row and column can be removed from the search space. We can achieve this by introducing another constraint: "Given `n` queens, find a configuration for the queens on an `n xx n` chessboard such that <strong>every row and column contains exactly one queen</strong> while maximizing the number of pairs of non-attacking queens."</p>
      <div class="ln-box">
        <p>Mathematically, for all `1 le i,j le n`, `Q_i != Q_j` and `i != j`.</p>
      </div>
      <p>Let's see how much the search space has been reduced by with this new constraint. Again, we'll first consider the `n=4` case.</p>
      <p>The first queen can only be placed in the first row, and in the first row, there are only `4` spaces for it. The second queen can only be placed in the second row, and in the second row, there are only `3` spaces for it. The third queen can only be placed in the third row, and in the third row, there are only `2` spaces for it. The last queen can only be placed in the fourth row, and in the fourth row, there is only `1` space for it. So there are a total of `4*3*2*1=24` possible board configurations.</p>
      <div class="ln-box">
        <p>In general, there are</p>
        <div class="ln-center">
          <p>`n!`</p>
        </div>
        <p>possible board configurations.</p>
      </div>
      <p>For the `n=8` case, there are now only `4032` board configurations in the search space.</p>
      <div class="ln-box">
        <p>Introducing constraints on the problem made the `n`-queens problem much easier to solve. However, even with the constraints, it is still a hard problem to solve, especially when `n` gets larger. Here's a table with the size of the search space for each version of the problem.</p>
        <div class="ln-center">
          <table class="table">
            <tr>
              <th>`n`</th>
              <th>free optimization</th>
              <th>`1` queen per row</th>
              <th>`1` queen per row and column</th>
            </tr>
            <tr>
              <td>`4`</td>
              <td>`43680`</td>
              <td>`256`</td>
              <td>`24`</td>
            </tr>
            <tr>
              <td>`8`</td>
              <td>`1.78643 xx 10^14`</td>
              <td>`16777216`</td>
              <td>`40320`</td>
            </tr>
            <tr>
              <td>`16`</td>
              <td>`2.10876 xx 10^38`</td>
              <td>`1.84467 xx 10^19`</td>
              <td>`2.09228 xx 10^13`</td>
            </tr>
            <tr>
              <td>`32`</td>
              <td>`1.30932 xx 10^96`</td>
              <td>`1.4615 xx 10^48`</td>
              <td>`2.63131 xx 10^35`</td>
            </tr>
            <tr>
              <td>`64`</td>
              <td>`9.4661 xx 10^230`</td>
              <td>`3.9402 xx 10^115`</td>
              <td>`1.26887 xx 10^89`</td>
            </tr>
          </table>
        </div>
      </div>
      <div class="ln-box">
        <p>So why are we even looking at the `n`-queens problem in the first place? It looks like a trivial puzzle.</p>
        <p>Well, it turns out that the `n`-queens problem has practical applications in things like task scheduling and computer resource management.</p>
      </div>
      <h2 id="evolutionarycomputing">Evolutionary Computing</h2>
      <p>Going through each possible board configuration to find a valid one is not practical. It would be better to programmatically generate solutions.</p>
      <p>One way of doing this is through evolutionary computing. Evolutionary computing is a research area within computer science that draws inspiration from evolution and natural selection.</p>
      <div class="ln-box">
        <p>Nature is apparently a good source of inspiration. The best problem solver known in nature is the human brain (basis of neurocomputing) and the evolutionary mechanism that created the human brain (basis of evolutionary computing).</p>
      </div>
      <p>The metaphor here is that the problem is like the environment; a candidate solution is like an individual; and the quality of the candidate solution is like the individual's "fitness" level.</p>
      <p>The population consists of candidate solutions and the best ones are selected for "reproduction". This produces new solutions (containing the traits from both of the parents), and those new solutions are modified slightly to maintain diversity. And this process repeats.</p>
      <div class="ln-center">
        <img class="img-fluid" src="../pictures/ai2/evolutionary_algorithm.png">
        <p>(image borrowed from my professor)</p>
      </div>
      <div class="ln-box">
        <p>The population is initialized by selecting a random subset of the search space.</p>
      </div>
      <p>There are two inherent, competing forces in evolutionary algorithms. The process of recombination (reproduction) and mutation promotes diversity and represents a push towards novelty. The process of selecting the fittest parents or survivors decreases diversity and represents a push towards quality. By going back and forth between these two forces, evolutionary algorithms balance exploration and exploitation to find optimal results.</p>
      <div class="ln-box">
        <p>Balancing exploration and exploitation is crucial to avoid inefficiency or premature convergence. Premature convergence is the effect of losing population diversity too quickly and getting trapped in a local minimum.</p>
      </div>
      <h3>Evolutionary Algorithm Components: Representation</h3>
      <p>Recall that earlier we were representing board configurations using coordinates and vectors (permutation encoding). In biological terms, what we were doing was mapping phenotypes (real-world solutions) to genotypes (encoded solutions).</p>
      <div class="ln-box">
        <p>A phenotype is the set of observable characteristics of an organism. A genotype is the complete set of genetic material of an organism.</p>
      </div>
      <div class="ln-box">
        <p>Continuing with the biology theme, a solution is called a chromosome. A chromosome contains genes, which contain the values of the chromosome. The actual values are called alleles.</p>
        <p>Loosely, genes are like the slots in a chromosome and the alleles are the values in those slots.</p>
      </div>
      <h3>Evolutionary Algorithm Components: Evaluation (Fitness) Function</h3>
      <p>Once we have encoded representations of the inputs, we can programmatically assess their quality. This is where the objective function we saw earlier comes in. </p>
      <div class="ln-box">
        <p>In the phenotype space, the function is called an objective function. In the genotype space, the function is called a fitness function.</p>
      </div>
      <p>The fitness function assigns a numerical value (referred to as fitness value) to each phenotype so that the algorithm can know which ones to select for recombination. Typically, the "fittest" individuals have high fitness values, so we seek to maximize fitness.</p>
      <div class="ln-box">
        <h3>Evolutionary Algorithm Components: Population</h3>
        <p>Formally, a population is a multiset of candidate solutions. This means that repeated elements are allowed to exist in the population.</p>
        <p>A population is considered to be the basic unit of evolution. So a population evolves, not single individuals.</p>
        <p>Diversity of a population can refer to either fitness diversity or phenotype/genotype diversity.</p>
      </div>
      <h3>Evolutionary Algorithm Components: Selection Mechanism</h3>
      <p>The selection mechanism compares the fitness values of the solutions to decide which ones become parents.</p>
      <p>Even though the general goal is to push the population towards higher fitness, the selection mechanism is usually probabilistic. Higher-quality solutions are more likely to be selected, but sub-optimal (or even the worst) solutions can still be picked.</p>
      <div class="ln-box">
        <p>Even though it might seem like it makes the most sense to just pick the solutions with the highest fitness values, it's sometimes necessary to not do that. Evolutionary algorithms can get stuck in a local maximum, and the only way to get out would be to pick sub-optimal solutions. Biologically, this is referred to as "genetic drift".</p>
      </div>
      <p>An example of a selection mechanism is a roulette wheel. Suppose we have three solutions `A, B, C`. `A` has a fitness of `3`; `B` has a fitness of `1`; `C` has a fitness of `2`. We can put them on a roulette wheel like so:</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/ai2/roulette_wheel.png">
      </div>
      <p>This way, `A`, which has the highest fitness value, has the highest chance of being selected.</p>
      <p>The selection mechanism is also responsible for replacing the elements in the population with survivors.</p>
      <p>While parent selection is usually probabilistic, survivor selection is usually deterministic. The process can be fitness based (compare the fitness values of the parents + offspring) or age based (replace as many parents as possible with offspring).</p>
      <h3>Evolutionary Algorithm Components: Recombination</h3>
      <p>Once the parents are selected, the offspring need to be produced. Recombination is the process of merging information from the parents into the offspring. The choice of what information to merge is random, so it's possible that the offspring can be worse or the same as the parents.</p>
      <h3>Evolutionary Algorithm Components: Termination</h3>
      <p>The algorithm has to stop eventually. There are several conditions we can use to determine when to stop:</p>
      <ul>
        <li>reaching some desired level of fitness</li>
        <li>reaching the maximum allowed number of generations</li>
        <li>reaching some level of diversity</li>
        <li>reaching some number of generations without fitness improvement</li>
      </ul>
      <h2 id="variationoperators">Variation Operators</h2>
      <p>Variation operators are genetic information manipulators that generate new candidate solutions. Mutation and recombination are the typical variation operators that are used in evolutionary algorithms. Variation operators are necessary for introducing diversity into the population.</p>
      <h3>Binary Representation</h3>
      <p>Suppose that we are encoding our solutions using strings of `1`s and `0`s (the genotype space is the set of strings of binary digits).</p>
      <div class="ln-box">
        <p>One problem we would do this for is the knapsack problem, in which we are deciding which items to put in a knapsack to maximize item value/count and minimize wasted bag space. A `1` would mean put the item in the knapsack and a `0` would mean don't.</p>
      </div>
      <h4>Mutation</h4>
      <p>One simple mutation we can do is to randomly flip bits. For example, `10100 rarr 00010`.</p>
      <div class="ln-box">
        <p>Formally, each bit has a probability `p_m` of flipping. `p_m` is referred to as the mutation rate. It's typically between `1/text(population size)` and `1/text(solution length)`.</p>
      </div>
      <div class="ln-box">
        <p>Using a lower probability preserves high-fitness individuals while using a higher probability encourages exploration (but risks disrupting good solutions). Generally, if we want to optimize overall population fitness, then we use a lower probability. If we want to find a single high-fitness individual, then using a higher probability can be better.</p>
      </div>
      <div class="ln-box">
        <p>There's an interesting problem with using binary. Consider the numbers `6`, `7`, and `8`, which are `0110`, `0111`, and `1000` in binary respectively.</p>
        <p>It takes only `1` bit flip to go from `0110` to `0111`, but it takes `4` bit flips to go from `0111` to `1000`. As a result, the probability of changing `7` to `8` is much less than the probability of changing `6` to `7`.</p>
        <p>Gray coding, which is a variation on the binary representation such that consecutive numbers differ in only one bit, helps with this problem.</p>
      </div>
      <h4>`1`-Point Crossover</h4>
      <p>One simple crossover technique we can do is to choose a random point and swap the parents' info at that point to produce the children.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray ln-red-right-border">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
        </tr>
        <tr>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td class="ln-red-right-border">`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
        </tr>
      </table>
      <p>Using the red line as the crossover point, we get</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
        </tr>
      </table>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
        </tr>
      </table>
      <div class="ln-box">
        <p>There is a positional bias when using a `1`-point crossover. Genes that are near each other are more likely to stay near each other and genes from opposite ends of the string can never be kept together.</p>
      </div>
      <h4>`n`-Point Crossover</h4>
      <p>Instead of picking just `1` split point, we can pick `n` split points.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray ln-red-right-border">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray ln-red-right-border">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray ln-red-right-border">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
        </tr>
        <tr>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td class="ln-red-right-border">`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td class="ln-red-right-border">`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td class="ln-red-right-border">`1`</td>
          <td>`1`</td>
        </tr>
      </table>
      <p>produces</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
        </tr>
      </table>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
        </tr>
      </table>
      <h4>Uniform Crossover</h4>
      <p>Another type of crossover we can do is to randomly pick genes from each parent. For the first child, each gene has a `50%` chance to come from one of the parents. Then the second child is created by flipping each gene of the first child.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
        </tr>
      </table>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
          <td>`1`</td>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`0`</td>
        </tr>
      </table>
      <h3>Integer Representation</h3>
      <p>Now let's look at variation operators for solutions that are encoded using more numbers than just `1` and `0`.</p>
      <div class="ln-box">
        <p>An example of a problem where we would use this type of encoding is graph coloring, where the goal is to color each vertex so that no two vertices share the same color. We would use numbers to represent each color.</p>
      </div>
      <h4>Mutation</h4>
      <p>For each gene, we could add a small (positive or negative) value with some probability `p`. We could also replace the gene with a random value with some probability `p`.</p>
      <h4>Recombination</h4>
      <p>The same recombination techniques we saw for the binary representation can be used for the integer representation as well.</p>
      <h3>Permutation Representation</h3>
      <p>Some problems, like the `n`-queens problem, require that solutions do not contain repeated values. For these types of problems, the order in which events occur matters a lot, like planning a route or scheduling jobs.</p>
      <h4>Swap Mutation</h4>
      <p>We can choose `2` alleles and swap them.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td>`3`</td>
          <td class="ln-red">`5`</td>
          <td>`4`</td>
          <td>`2`</td>
          <td>`8`</td>
          <td class="ln-red">`7`</td>
          <td>`6`</td>
        </tr>
      </table>
      <div class="ln-center">
        <p>`darr`</p>
      </div>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td>`3`</td>
          <td class="ln-red">`7`</td>
          <td>`4`</td>
          <td>`2`</td>
          <td>`8`</td>
          <td class="ln-red">`5`</td>
          <td>`6`</td>
        </tr>
      </table>
      <h4>Insert Mutation</h4>
      <p>We can choose `2` alleles and move the second one up to the first one.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`2`</td>
          <td>`3`</td>
          <td>`4`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td>`6`</td>
          <td>`7`</td>
          <td>`8`</td>
        </tr>
      </table>
      <div class="ln-center">
        <p>`darr`</p>
      </div>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`2`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td>`3`</td>
          <td>`4`</td>
          <td>`6`</td>
          <td>`7`</td>
          <td>`8`</td>
        </tr>
      </table>
      <h4>Scramble Mutation</h4>
      <p>We can pick a subset of genes and randomly rearrange the alleles in those positions.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`2`</td>
          <td class="ln-white ln-bg-gray">`3`</td>
          <td class="ln-white ln-bg-gray">`4`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td>`6`</td>
          <td>`7`</td>
          <td>`8`</td>
        </tr>
      </table>
      <div class="ln-center">
        <p>`darr`</p>
      </div>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`3`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td class="ln-white ln-bg-gray">`4`</td>
          <td class="ln-white ln-bg-gray">`2`</td>
          <td>`6`</td>
          <td>`7`</td>
          <td>`8`</td>
        </tr>
      </table>
      <div class="ln-box">
        <p>These types of mutations (swap, insert, scramble) are preferred for order-based problems, i.e., problems where the order of events are important.</p>
      </div>
      <h4>Inversion Mutation</h4>
      <p>We can pick `2` alleles and invert the substring between them.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`2`</td>
          <td class="ln-white ln-bg-gray">`3`</td>
          <td class="ln-white ln-bg-gray">`4`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td>`6`</td>
          <td>`7`</td>
          <td>`8`</td>
        </tr>
      </table>
      <div class="ln-center">
        <p>`darr`</p>
      </div>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td class="ln-white ln-bg-gray">`4`</td>
          <td class="ln-white ln-bg-gray">`3`</td>
          <td class="ln-white ln-bg-gray">`2`</td>
          <td>`6`</td>
          <td>`7`</td>
          <td>`8`</td>
        </tr>
      </table>
      <div class="ln-box">
        <p>This preserves most of the adjacency information (since it only breaks `2` links) but it is disruptive for the order information.</p>
      </div>
      <div class="ln-box">
        <p>When performing mutations on permutations, we can't consider each gene independently since it might mess up the permutation. So the mutation parameter is the probability that a chromosome undergoes mutation, instead of the probability that each gene undergoes mutation, like in the binary and integer case.</p>
      </div>
      <h4>Partially Mapped Crossover (PMX)</h4>
      <div class="ln-box">
        <p>Doing a simple crossover for permutations isn't straightforward. It was implied in the `8`-queens problem, but doing a simple substring swap(s) will most likely not preserve the permutation property.</p>
      </div>
      <p>Suppose we have two parents</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td>`2`</td>
          <td>`3`</td>
          <td>`4`</td>
          <td>`5`</td>
          <td>`6`</td>
          <td>`7`</td>
          <td>`8`</td>
          <td>`9`</td>
        </tr>
      </table>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`9`</td>
          <td>`3`</td>
          <td>`7`</td>
          <td>`8`</td>
          <td>`2`</td>
          <td>`6`</td>
          <td>`5`</td>
          <td>`1`</td>
          <td>`4`</td>
        </tr>
      </table>
      <p>The first step of PMX is to choose `2` crossover points and copy the segment between them from the first parent into the first child.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td>`2`</td>
          <td>`3`</td>
          <td class="ln-white ln-bg-gray">`4`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td class="ln-white ln-bg-gray">`6`</td>
          <td class="ln-white ln-bg-gray">`7`</td>
          <td>`8`</td>
          <td>`9`</td>
        </tr>
        <tr>
          <td>`9`</td>
          <td>`3`</td>
          <td>`7`</td>
          <td class="ln-white ln-bg-gray">`8`</td>
          <td class="ln-white ln-bg-gray">`2`</td>
          <td class="ln-white ln-bg-gray">`6`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td>`1`</td>
          <td>`4`</td>
        </tr>
      </table>
      <p>First child:</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td class="ln-white ln-bg-gray">`4`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td class="ln-white ln-bg-gray">`6`</td>
          <td class="ln-white ln-bg-gray">`7`</td>
          <td>-</td>
          <td>-</td>
        </tr>
      </table>
      <p>The second step is to look at the segment in the second parent and see which values weren't copied over to the first child. In this example, `8` and `2`.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td>`2`</td>
          <td>`3`</td>
          <td class="ln-white ln-bg-gray">`4`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td class="ln-white ln-bg-gray">`6`</td>
          <td class="ln-white ln-bg-gray">`7`</td>
          <td>`8`</td>
          <td>`9`</td>
        </tr>
        <tr>
          <td>`9`</td>
          <td>`3`</td>
          <td>`7`</td>
          <td class="ln-light-blue ln-bg-gray">`8`</td>
          <td class="ln-light-blue ln-bg-gray">`2`</td>
          <td class="ln-white ln-bg-gray">`6`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td>`1`</td>
          <td>`4`</td>
        </tr>
      </table>
      <p>What we do with these uncopied values is best explained with a visual.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/ai2/pmx.gif">
      </div>
      <p>The last step is to copy the remaining values from the second parent into the same positions in the first child.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td>`2`</td>
          <td>`3`</td>
          <td class="ln-white ln-bg-gray">`4`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td class="ln-white ln-bg-gray">`6`</td>
          <td class="ln-white ln-bg-gray">`7`</td>
          <td>`8`</td>
          <td>`9`</td>
        </tr>
        <tr>
          <td class="ln-red">`9`</td>
          <td class="ln-red">`3`</td>
          <td>`7`</td>
          <td class="ln-white ln-bg-gray">`8`</td>
          <td class="ln-white ln-bg-gray">`2`</td>
          <td class="ln-white ln-bg-gray">`6`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td class="ln-red">`1`</td>
          <td>`4`</td>
        </tr>
      </table>
      <p>First child:</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`9`</td>
          <td>`3`</td>
          <td>`2`</td>
          <td class="ln-white ln-bg-gray">`4`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td class="ln-white ln-bg-gray">`6`</td>
          <td class="ln-white ln-bg-gray">`7`</td>
          <td>`1`</td>
          <td>`8`</td>
        </tr>
      </table>
      <p>The second child is produced the same way, just with the parent roles reversed (so the second parent's segment is copied into the second child as the first step).</p>
      <h4>Order `1` Crossover</h4>
      <p>The first step of the order `1` crossover is the same as the first step of PMX: choose `2` crossover points and copy the segment between them from the first parent into the first child.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td>`2`</td>
          <td>`3`</td>
          <td class="ln-white ln-bg-gray">`4`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td class="ln-white ln-bg-gray">`6`</td>
          <td class="ln-white ln-bg-gray">`7`</td>
          <td>`8`</td>
          <td>`9`</td>
        </tr>
        <tr>
          <td>`9`</td>
          <td>`3`</td>
          <td>`7`</td>
          <td class="ln-white ln-bg-gray">`8`</td>
          <td class="ln-white ln-bg-gray">`2`</td>
          <td class="ln-white ln-bg-gray">`6`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td>`1`</td>
          <td>`4`</td>
        </tr>
      </table>
      <p>First child:</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td class="ln-white ln-bg-gray">`4`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td class="ln-white ln-bg-gray">`6`</td>
          <td class="ln-white ln-bg-gray">`7`</td>
          <td>-</td>
          <td>-</td>
        </tr>
      </table>
      <p>Then we copy the values from the second parent that weren't copied over yet, starting from the right of the rightmost crossover point and wrapping around to the beginning when we reach the end.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/ai2/order_1_crossover.gif">
      </div>
      <p>First child:</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`3`</td>
          <td>`8`</td>
          <td>`2`</td>
          <td class="ln-white ln-bg-gray">`4`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td class="ln-white ln-bg-gray">`6`</td>
          <td class="ln-white ln-bg-gray">`7`</td>
          <td>`1`</td>
          <td>`9`</td>
        </tr>
      </table>
      <p>The second child is produced the same way, just with the parent roles reversed (so the second parent's segment is copied into the second child as the first step).</p>
      <div class="ln-box">
        <p>The goal of order crossover is to transmit information about relative order from the second parent.</p>
      </div>
      <h4>Cycle Crossover</h4>
      <p>For this crossover technique, we copy cycles from the parents into the children. Cycles are found using the same visual method in PMX.</p>
      <p>Cycle 1:</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/ai2/cycle_crossover_1.gif">
        <p>I (obviously) reused the same image and forgot to remove the "Child `1`".</p>
      </div>
      <p>Cycle 2:</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/ai2/cycle_crossover_2.gif">
        <p>I (obviously) reused the same image and forgot to remove the "Child `1`".</p>
      </div>
      <p>So we take the values involved in the first cycle and copy them into the children in their respective positions.</p>
      <p>First child:</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td class="ln-white ln-bg-gray">`1`</td>
          <td>-</td>
          <td>-</td>
          <td class="ln-white ln-bg-gray">`4`</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td class="ln-white ln-bg-gray">`8`</td>
          <td class="ln-white ln-bg-gray">`9`</td>
        </tr>
      </table>
      <p>Second child:</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td class="ln-white ln-bg-gray">`9`</td>
          <td>-</td>
          <td>-</td>
          <td class="ln-white ln-bg-gray">`8`</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td class="ln-white ln-bg-gray">`1`</td>
          <td class="ln-white ln-bg-gray">`4`</td>
        </tr>
      </table>
      <p>Then we take the values involved in the second cycle and copy them into the children, but in the opposite positions (so the values from the first parent go into the second child and the values from the second parent go into the first child).</p>
      <p>First child:</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td class="ln-white ln-bg-gray">`3`</td>
          <td class="ln-white ln-bg-gray">`7`</td>
          <td>`4`</td>
          <td class="ln-white ln-bg-gray">`2`</td>
          <td>-</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td>`8`</td>
          <td>`9`</td>
        </tr>
      </table>
      <p>Second child:</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`9`</td>
          <td class="ln-white ln-bg-gray">`2`</td>
          <td class="ln-white ln-bg-gray">`3`</td>
          <td>`8`</td>
          <td class="ln-white ln-bg-gray">`5`</td>
          <td>-</td>
          <td class="ln-white ln-bg-gray">`7`</td>
          <td>`1`</td>
          <td>`4`</td>
        </tr>
      </table>
      <p>Then we take the values involved in the third cycle and copy them into the children in their respective positions.</p>
      <p>First child:</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td>`3`</td>
          <td>`7`</td>
          <td>`4`</td>
          <td>`2`</td>
          <td class="ln-white ln-bg-gray">`6`</td>
          <td>`5`</td>
          <td>`8`</td>
          <td>`9`</td>
        </tr>
      </table>
      <p>Second child:</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`9`</td>
          <td>`2`</td>
          <td>`3`</td>
          <td>`8`</td>
          <td>`5`</td>
          <td class="ln-white ln-bg-gray">`6`</td>
          <td>`7`</td>
          <td>`1`</td>
          <td>`4`</td>
        </tr>
      </table>
      <p>And we keep repeating this alternating pattern until we're done.</p>
      <div class="ln-box">
        <p>The goal of cycle crossover is to transmit information about the absolute position in which elements occur.</p>
      </div>
      <div class="ln-box">
        <h3>Real-Valued/Floating-Point Representation</h3>
        <p>A solution is represented as a vector `[x_1, x_2, ..., x_k]^T` where each `x_i in RR`.</p>
        <h4>Uniform Mutation</h4>
        <p>We could replace each element with a randomly-selected value from some predefined range of values. (This is similar to bit flipping in the binary representation and random resetting in the integer representation.)</p>
        <p>Uniform mutation is most suitable when the genes encode cardinal attributes, since all values are equally likely to be chosen.</p>
        <h4>Nonuniform Mutation</h4>
        <p>The most common method is to add a random delta to each gene, where the delta is taken from a Gaussian distribution with mean `0` and standard deviation `sigma`.</p>
        <div class="ln-center">
          <p>`x_i' = x_i + N(0, sigma)`</p>
        </div>
        <p>`sigma` is the standard deviation (also referred to here as the mutation step size) and it controls how big the deltas are.</p>
        <h4>Discrete Crossover</h4>
        <p>A simple crossover technique is to take an allele from one of the parents with equal probability.</p>
        <h4>Intermediate Crossover (Arithmetic Recombination)</h4>
        <p>Since we're dealing with real numbers, we can create children that are "between" the parents. For two parents `x,y`, we can create a child `z` using</p>
        <div class="ln-center">
          <p>`z_i = alpha x_i + (1-alpha) y_i`</p>
          <p>for `0 le alpha le 1`</p>
        </div>
        <p>where `alpha` can be constant, variable, or picked randomly every time.</p>
        <h5>Single Arithmetic Crossover</h5>
        <p>We can do this for only one gene:</p>
        <div class="ln-center">
          <p>`[x_1, ..., x_(k-1), alpha*y_k+(1-alpha)*x_k,...,x_n]`</p>
          <p>(exact copy of parent `x` except for the `k^(th)` gene)</p>
        </div>
        <h5>Simple Arithmetic Crossover</h5>
        <p>For several genes:</p>
        <div class="ln-center">
          <p>`[x_1, ..., x_k, alpha*y_(k+1)+(1-alpha)*x_(k+1),...,alpha*y_n+(1-alpha)*x_n]`</p>
          <p>(exact copy of parent `x` except for genes `k+1` to `n`)</p>
        </div>
        <h5>Whole Arithmetic Crossover</h5>
        <p>Or for all the genes:</p>
        <div class="ln-center">
          <p>`z=alpha*x+(1-alpha)*y`</p>
        </div>
      </div>
      <div class="ln-box">
        <h3>Crossover vs. Mutation</h3>
        <p>Crossover is explorative and mutation is exploitative.</p>
        <p>Only crossovers can combine information from two parents.</p>
        <p>Only mutation can introduce new information.</p>
        <p>Hitting the optimum usually requires a lucky mutation.</p>
      </div>
      <h2 id="selectionoperators">Selection Operators</h2>
      <p>Selection operators are used for population management. They decide which individuals in the population are selected for mating (parent selection) and which individuals in the population survive (survivor selection).</p>
      <p>Selection pressure is the intensity with which fitter individuals are favored over worse individuals. A higher selection pressure means that fitter individuals are more favored, and a lower selection pressure means that worse individuals have a higher chance of being selected.</p>
      <h3>Parent Selection</h3>
      <h4>Fitness Proportional Selection</h4>
      <p>For parent selection, it's natural to want to use higher-fitness individuals for mating. But, as mentioned before, using only high-fitness individuals can have problems with getting stuck at local optima.</p>
      <p>Fitness proportional selection is a probabilistic method that selects individuals for mating by their absolute fitness values. Individuals with a higher fitness have a higher chance of being selected. And since we're looking at absolute fitness values, individuals with much higher fitness have a much higher chance of being selected.</p>
      <div class="ln-center">
        <p>`P_(FPS)(i)=f_i/(sum_(j=1)^(mu)f_j)`</p>
      </div>
      <p>For example, suppose we have some individuals `x=1, x=2, x=3` with their fitness values given below.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <th>`x`</th>
          <th>fitness</th>
        </tr>
        <tr>
          <td>`1`</td>
          <td>`1`</td>
        </tr>
        <tr>
          <td>`2`</td>
          <td>`4`</td>
        </tr>
        <tr>
          <td>`3`</td>
          <td>`9`</td>
        </tr>
      </table>
      <p>We could simulate fitness proportional selection by making copies of each individual based on their fitness values. This way, if we select one copy, the probability that the copy is going to have a high fitness value is high. Individual `x=3` has a `9/14` chance of being selected versus individual `x=1`, which only has a `1/14` chance of being selected.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <td>`1`</td>
          <td>`2`</td>
          <td>`2`</td>
          <td>`2`</td>
          <td>`2`</td>
          <td>`3`</td>
          <td>`3`</td>
          <td>`3`</td>
          <td>`3`</td>
          <td>`3`</td>
          <td>`3`</td>
          <td>`3`</td>
          <td>`3`</td>
          <td>`3`</td>
        </tr>
      </table>
      <p>One of the disadvantages of using fitness proportional selection is that it could lead to premature convergence. Since higher-fitness individuals have a significantly higher chance of being selected, the population could quickly lose diversity and converge to a single solution.</p>
      <p>Another disadvantage of fitness proportional selection is that it is highly susceptible to function transposition. Consider the following fitness values and selection probabilities.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <th>Individual</th>
          <th>Fitness for `f`</th>
          <th>Selection probability for `f`</th>
          <th>Fitness for `f+10`</th>
          <th>Selection probability for `f+10`</th>
          <th>Fitness for `f+100`</th>
          <th>Selection probability for `f+100`</th>
        </tr>
        <tr>
          <td>`A`</td>
          <td>`1`</td>
          <td>`0.1`</td>
          <td>`11`</td>
          <td>`0.275`</td>
          <td>`101`</td>
          <td>`0.326`</td>
        </tr>
        <tr>
          <td>`B`</td>
          <td>`4`</td>
          <td>`0.4`</td>
          <td>`14`</td>
          <td>`0.35`</td>
          <td>`104`</td>
          <td>`0.335`</td>
        </tr>
        <tr>
          <td>`C`</td>
          <td>`5`</td>
          <td>`0.5`</td>
          <td>`15`</td>
          <td>`0.375`</td>
          <td>`105`</td>
          <td>`0.339`</td>
        </tr>
        <tr>
          <td>Sum</td>
          <td>`10`</td>
          <td>`1.0`</td>
          <td>`40`</td>
          <td>`1.0`</td>
          <td>`310`</td>
          <td>`1.0`</td>
        </tr>
      </table>
      <p>We can see the selection probabilities don't stay proportional to the fitness values as we change the fitness values. `C` is `4` points higher than `A`, and in the simple case of `f`, has a much higher chance of being selected. In the case of `f+100`, `C` is still `4` points higher than `A`, but `C` has virtually the same chance of being selected as `A`.</p>
      <h5>Windowing</h5>
      <p>One way of dealing with this is to use windowing. Windowing is a method that adjusts the fitness values dynamically to maintain the fitness differentials.</p>
      <p>Let `beta^t` be the worst fitness in the `t^(th)` generation. We adjust the fitness values every generation by using</p>
      <div class="ln-center">
        <p>`f'(i)=f(i)-beta^t`</p>
      </div>
      <p>This essentially makes it so that the worst individual has a zero chance of being picked while still allowing high-fitness invidivudals to maintain their high probability.</p>
      <h5>Sigma Scaling</h5>
      <p>Sigma scaling adjusts the fitness values by incorporating the population variance. Let `bar f` be the mean of the fitness values, `sigma_f` be the standard deviation, and `c` be some constant value (usually `2`). We adjust the fitness values every generation by using</p>
      <div class="ln-center">
        <p>`f'(i)=max(0, f(i)-(bar f - c*sigma_f))`</p>
      </div>
      <h4>Rank-based Selection</h4>
      <p>Of course, we could avoid the problems of fitness proportional selection by using something else entirely. Instead of looking at absolute fitness, we could look at relative fitness.</p>
      <p>For example, in the earlier example, `x=1` had a `1/14` chance of being selected and `x=3` had a `9/14` chance of being selected. Looking at absolute fitness, `x=3` is `9` times more likely to be selected than `x=1`.</p>
      <p>If we want to look at relative fitness, let's assign some rank to these individuals, say rank `2` to `x=3`, rank `1` to `x=2`, and rank `0` to `x=1` (so the higher the rank, the higher the fitness). Assigning a rank allows us to know which individual is the fittest without being biased by how much fitter an individual is.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <th>`x`</th>
          <th>fitness</th>
          <th>rank</th>
        </tr>
        <tr>
          <td>`1`</td>
          <td>`1`</td>
          <td>`0`</td>
        </tr>
        <tr>
          <td>`2`</td>
          <td>`4`</td>
          <td>`1`</td>
        </tr>
        <tr>
          <td>`3`</td>
          <td>`9`</td>
          <td>`2`</td>
        </tr>
      </table>
      <div class="ln-box">
        <p>Ranking introduces a sorting overhead, but this is usually negligible compared to the overhead of computing fitness values.</p>
      </div>
      <div class="ln-box">
        <h5>Linear Ranking</h5>
        <div class="ln-center">
          <p>`P(i)=(2-s)/mu+(2i(s-1))/(mu(mu-1))`</p>
        </div>
        <p>`s` is the selection pressure, and it ranges from `1 lt s le 2`. Using a higher selection pressure favors fitter individuals.</p>
        <table class="table table-bordered ln-center">
          <tr>
            <th>Individual</th>
            <th>Fitness</th>
            <th>Rank</th>
            <th>`P_(FPS)`</th>
            <th>`P_(LR)` for `s=2`</th>
            <th>`P_(LR)` for `s=1.5`</th>
          </tr>
          <tr>
            <td>`A`</td>
            <td>`1`</td>
            <td>`0`</td>
            <td>`0.1`</td>
            <td>`0`</td>
            <td>`0.167`</td>
          </tr>
          <tr>
            <td>`B`</td>
            <td>`4`</td>
            <td>`1`</td>
            <td>`0.4`</td>
            <td>`0.33`</td>
            <td>`0.33`</td>
          </tr>
          <tr>
            <td>`C`</td>
            <td>`5`</td>
            <td>`2`</td>
            <td>`0.5`</td>
            <td>`0.67`</td>
            <td>`0.5`</td>
          </tr>
          <tr>
            <td>Sum</td>
            <td>`10`</td>
            <td>-</td>
            <td>`1.0`</td>
            <td>`1.0`</td>
            <td>`1.0`</td>
          </tr>
        </table>
        <p>One limitation with linear ranking is that the selection pressure is limited. It can only take on values between `1` and `2`*. So the fittest individual only has at most a `2` times higher chance of being selected.</p>
        <p>*Having `s gt 2` would lead to negative probabilities for less fit individuals since all the probabilities have to add up to `1`.</p>
        <h5>Exponential Ranking</h5>
        <div class="ln-center">
          <p>`P(i)=(1-e^(-i))/c`</p>
        </div>
        <p>where `c` is a normalization constant that ensures the sum of all the probabilities add up to `1`.</p>
        <p>Exponential ranking is preferred over linear ranking when we want the fittest individuals to have more chances of being selected. This is helpful in situations where it is really costly to compute fitness values, so we only want to spend resources calculating fitness values for individuals that are worth calculating.</p>
      </div>
      <h4>Tournament Selection</h4>
      <p>If the population is very large, then it can be very expensive to keep computing the fitness of the whole population. Instead, we can pick `k` members at random and then select the best individuals from that sample.</p>
      <p>The probability of selecting an individual `i` is based on several factors:</p>
      <ul>
        <li>the rank of `i`</li>
        <li>`k`, the size of the sample
          <ul>
            <li>a higher `k` increases selection pressure</li>
          </ul>
        </li>
        <li>whether individuals are picked with replacement
          <ul>
            <li>picking without replacement increases selection pressure</li>
          </ul>
        </li>
        <li>whether the fittest individual always wins (deterministic) or whether they win probabilistically</li>
      </ul>
      <h3>Population Management</h3>
      <p>When the selected parents produce offspring, they have to replace individuals in the population to maintain the population size.</p>
      <div class="ln-box">
        <p>We'll use `mu` for the population size and `lambda` for the number of offspring.</p>
      </div>
      <h4>Generational Model</h4>
      <p>In the generational model, the whole population is replaced (assuming two parents produce two children). This results in a faster exploration of the search space. But it is also more likely to remove good traits from the population that are beneficial for producing good solutions.</p>
      <div class="ln-box">
        <p>For each generation, `lambda=mu`.</p>
      </div>
      <h4>Steady-State Model</h4>
      <p>In the steady-state model, only some of the population is replaced. The proportion of the population that is replaced is called the generational gap (represented by `lambda/mu`).</p>
      <div class="ln-box">
        <p>For each generation, `lambda lt mu`.</p>
      </div>
      <h3>Survivor Selection</h3>
      <p>The selection methods for selecting individuals to be replaced can be age-based or fitness-based. Age-based methods are not interesting, so we'll only look at fitness-based ones.</p>
      <h4>Elitism</h4>
      <p>As the name suggests, the fittest individuals remain in the population while less fit individuals are replaced. This ensures that there is always at least one copy of the fittest solution in the population.</p>
      <h4>GENITOR (Delete Worst)</h4>
      <p>As the name suggests, the worst members of the population are selected for replacement. To be honest, I still don't understand the difference between elitism and GENITOR.</p>
      <h4>Round-Robin Tournament</h4>
      <p>Here, the offspring is merged with the population and they duke it out with each other to see who wins. Each individual is evaluated against `q` other randomly chosen individuals. The individuals with the most wins stay in the population.</p>
      <div class="ln-box">
        <p>When `q` is large, the selection pressure is higher since stronger individuals are more likely to survive. `q` is typically `10`.</p>
      </div>
      <h4>`(mu,lambda)`-Selection</h4>
      <p>From what I understand, `mu` parents generate `lambda` offspring, and only the best `mu` children are selected to replace the whole population. (This requires `lambda gt mu`.)</p>
      <h4>`(mu+lambda)`-Selection</h4>
      <p>Here, the offspring is merged with the population and the best `mu` individuals survive.</p>
      <h3>Selection Pressure</h3>
      <p>As mentioned earlier, the idea behind selection pressure is that fitter individuals are more likely to survive or be chosen as parents.</p>
      <p>Selection pressure can be quantified by a measure called takeover time (denoted as `tau^(ast)`). Takeover time is the number of generations it takes for the fittest individual to take over the entire population.</p>
      <p>The general formula for takeover time is</p>
      <div class="ln-center">
        <p>`tau^(ast)=ln(lambda)/ln(lambda/mu)`</p>
      </div>
      <p>For example, for `mu=15` and `lambda=100`, `tau^(ast)~~2`, which means that in `2` generations, every individual will be the same (the best individual).</p>
      <div class="ln-box">
        <p>For fitness proportional selection, the takeover time is</p>
        <div class="ln-center">
          <p>`tau^(ast)=lambda ln(lambda)`</p>
        </div>
      </div>
      <h2 id="eavariants">Evolutionary Algorithm Variants</h2>
      <p>As we've seen, there are many choices for which representation, selection operators, and variation operators to use. The set of choices that are used defines an "instance" of an evolutionary algorithm.</p>
      <p>Historically, many different types of evolutionary algorithms have been developed.</p>
      <h3>Genetic Algorithms</h3>
      <p>The genetic algorithm (GA) was developed in the 1960s by Holland in his study of adaptive behavior.</p>
      <table class="table table-bordered">
        <tr>
          <td>Representation</td>
          <td>Bit-strings</td>
        </tr>
        <tr>
          <td>Recombination</td>
          <td>1-Point crossover</td>
        </tr>
        <tr>
          <td>Mutation</td>
          <td>Bit flip</td>
        </tr>
        <tr>
          <td>Parent selection</td>
          <td>Fitness proportional - implemented by Roulette Wheel</td>
        </tr>
        <tr>
          <td>Survivor selection</td>
          <td>Generational</td>
        </tr>
      </table>
      <p>The mutation probability is typically low since there is more emphasis on recombination as the preferred way of generating offspring.</p>
      <p>GA is typically used for straightforward binary representation problems, function optimization, and teaching evolutionary algorithms.</p>
      <h3>Evolution Strategies</h3>
      <p>Evolution strategies (ES) were developed in the 1960s by Rechenberg and Schwefel in their study of shape optimization.</p>
      <table class="table table-bordered">
        <tr>
          <td>Representation</td>
          <td>Real-valued vectors</td>
        </tr>
        <tr>
          <td>Recombination</td>
          <td>Discrete or intermediary</td>
        </tr>
        <tr>
          <td>Mutation</td>
          <td>Gaussian perturbation</td>
        </tr>
        <tr>
          <td>Parent selection</td>
          <td>Uniform random</td>
        </tr>
        <tr>
          <td>Survivor selection</td>
          <td>Deterministic elitist replacement by `(mu, lambda)` or `(mu+lambda)`</td>
        </tr>
        <tr>
          <td>Specialty</td>
          <td>Self-adaptation of mutation step sizes</td>
        </tr>
      </table>
      <p>Self-adaptation means that the mutation step size changes from generation to generation. This is implemented by Rechenberg's `1//5` success rule, which scales `sigma` by a factor depending on the success rate of a mutation (whatever that means).</p>
      <div class="ln-box">
        <p>Here are some different types of recombination methods. `i` is the index of the gene, `x` and `y` are the parents, and `z` is the child.</p>
        <table class="table table-bordered ln-center">
          <tr>
            <th></th>
            <th>Two fixed parents</th>
            <th>Two parents selected for each `i`</th>
          </tr>
          <tr>
            <th>`z_i=(x_i+y_i)/2`</th>
            <td>local intermediary</td>
            <td>global intermediary</td>
          </tr>
          <tr>
            <th>`z_i` is `x_i` or `y_i` chosen randomly</th>
            <td>local discrete</td>
            <td>global discrete</td>
          </tr>
        </table>
        <p>ESs typically use global recombination.</p>
      </div>
      <div class="ln-box">
        <p>`(mu,lambda)` selection is generally preferred over `(mu+lambda)` selection because `(mu+lambda)` has a tendency to keep bad solutions (and the traits that produce the bad solutions) around for a large number of generations.</p>
      </div>
      <p>ESs are typically used for numerical optimization and shape optimization.</p>
      <h3>Evolutionary Programming</h3>
      <p>Evolutionary programming (EP) was developed in the 1960s by Fogel et al. in their study of generating artificial intelligence (by attempting to simulate evolution as a learning process).</p>
      <table class="table table-bordered">
        <tr>
          <td>Representation</td>
          <td>Real-valued vectors</td>
        </tr>
        <tr>
          <td>Recombination</td>
          <td>None</td>
        </tr>
        <tr>
          <td>Mutation</td>
          <td>Gaussian perturbation</td>
        </tr>
        <tr>
          <td>Parent selection</td>
          <td>Deterministic (each parent creates one offspring via mutation)</td>
        </tr>
        <tr>
          <td>Survivor selection</td>
          <td>Probabilistic `(mu+mu)`</td>
        </tr>
        <tr>
          <td>Specialty</td>
          <td>Self-adaptation of mutation step sizes</td>
        </tr>
      </table>
      <p>The notable thing about EP is that there is no recombination. This is because each individual is seen as a distinct species, so it doesn't make sense theoretically to perform recombination. This also means that only `1` parent is needed to produce a child, so there's not really a parent selection mechanism.</p>
      <div class="ln-box">
        <p>This has, of course, led to much debate and study on the performance of algorithms with and without recombination.</p>
      </div>
      <p>Survivor selection is implemented using stochastic round-robin tournaments.</p>
      <p>EP is typically used for numerical optimization.</p>
      <h3>Genetic Programming</h3>
      <p>Genetic programming (GP) was developed in the 1990s by Koza.</p>
      <table class="table table-bordered">
        <tr>
          <td>Representation</td>
          <td>Tree structures</td>
        </tr>
        <tr>
          <td>Recombination</td>
          <td>Exchange of subtrees</td>
        </tr>
        <tr>
          <td>Mutation</td>
          <td>Random change in trees</td>
        </tr>
        <tr>
          <td>Parent selection</td>
          <td>Fitness proportional</td>
        </tr>
        <tr>
          <td>Survivor selection</td>
          <td>Generational replacement</td>
        </tr>
      </table>
      <p>Similarly to GA, the mutation probability is low for GP. In fact, Koza suggested using a mutation rate of `0%`. The idea behind not needing mutation is that recombination already has a large shuffling effect, so it's kind of a mutation operator already.</p>
      <div class="ln-box">
        <p>For large population sizes, over-selection is a method that is used for parent selection.</p>
        <p>The population is ranked by fitness, then split into two groups. One group contains the top `x%` and the other contains the remaining `(100-x)%`. `80%` of the selection operations come from the first group, and the other `20%` come from the other group.</p>
      </div>
      <p>GP is typically used for machine learning tasks, like prediction and classification.</p>
      <h3>Differential Evolution</h3>
      <p>Differential evolution (DE) was developed in 1995 by Storn and Price.</p>
      <table class="table table-bordered">
        <tr>
          <td>Representation</td>
          <td>Real-valued vectors</td>
        </tr>
        <tr>
          <td>Recombination</td>
          <td>Uniform crossover (with crossover probability `C_r`)</td>
        </tr>
        <tr>
          <td>Mutation</td>
          <td>Differential mutation</td>
        </tr>
        <tr>
          <td>Parent selection</td>
          <td>Uniform random selection of the `3` necessary vectors</td>
        </tr>
        <tr>
          <td>Survivor selection</td>
          <td>Deterministic elitist replacement (parent vs. child)</td>
        </tr>
      </table>
      <p>The notable thing about DE is that `3` parents are needed to create a new child. We can see why when we look at how differential mutation works. Basically, the vector difference of two parents is added to another parent to produce the child.</p>
      <p>Let `x,y,z` be the parents. The scaled vector difference of `y` and `z` is denoted as `p`, the perturbation vector. The child produced is denoted `x'`. `F` is the scaling factor that controls the rate at which the population evolves.</p>
      <div class="ln-center">
        <p>`p = F*(y-z)`</p>
        <p>`x' = x + p`</p>
      </div>
      <p>For recombination, uniform crossover is used, meaning that each gene either comes from the first parent or the second parent. But there is a slight difference from the usual uniform crossover; there is a crossover probability `C_r in [0,1]` that decides the probability of picking the gene from the first parent.</p>
      <p>DE is typically applied to nonlinear and nondifferentiable continuous space functions.</p>
      <h2 id="parametertuning">Parameters and Parameter Tuning</h2>
      <p>Each evolutionary algorithm variant differs in their choices for which operators to use. These choices are the parameters of the algorithm. There are two categories of parameters: symbolic parameters and numeric parameters.</p>
      <p>Symbolic parameters are the categorical aspects of the algorithm. For example, what type of parent selection should be used? Or what type of recombination should be used?</p>
      <p>Numeric parameters are the, well, numeric aspects of the algorithm. For example, what should the population size be? Or what should be the mutation probability?</p>
      <p>Here's an example with three evolutionary algorithm instances `A_1`, `A_2`, and `A_3`.</p>
      <table class="table table-bordered ln-center">
        <tr>
          <th></th>
          <th>`A_1`</th>
          <th>`A_2`</th>
          <th>`A_3`</th>
        </tr>
        <tr>
          <th colspan="4">symbolic parameters</th>
        </tr>
        <tr>
          <th>representation</th>
          <td>bitstring</td>
          <td>bitstring</td>
          <td>real-valued</td>
        </tr>
        <tr>
          <th>recombination</th>
          <td>`1`-point</td>
          <td>`1`-point</td>
          <td>averaging</td>
        </tr>
        <tr>
          <th>mutation</th>
          <td>bit-flip</td>
          <td>bit-flip</td>
          <td>Gaussian `N(0,sigma)`</td>
        </tr>
        <tr>
          <th>parent selection</th>
          <td>tournament</td>
          <td>tournament</td>
          <td>uniform random</td>
        </tr>
        <tr>
          <th>survivor selection</th>
          <td>generational</td>
          <td>generational</td>
          <td>`(mu,lambda)`</td>
        </tr>
        <tr>
          <th colspan="4">numeric parameters</th>
        </tr>
        <tr>
          <th>`p_m`</th>
          <td>`0.01`</td>
          <td>`0.1`</td>
          <td>`0.05`</td>
        </tr>
        <tr>
          <th>`sigma`</th>
          <td>n.a.</td>
          <td>n.a.</td>
          <td>`0.1`</td>
        </tr>
        <tr>
          <th>`p_c`</th>
          <td>`0.5`</td>
          <td>`0.7`</td>
          <td>`0.7`</td>
        </tr>
        <tr>
          <th>`mu`</th>
          <td>`100`</td>
          <td>`100`</td>
          <td>`10`</td>
        </tr>
        <tr>
          <th>`lambda`</th>
          <td>equal `mu`</td>
          <td>equal `mu`</td>
          <td>`70`</td>
        </tr>
        <tr>
          <th>`k`</th>
          <td>`2`</td>
          <td>`4`</td>
          <td>n.a.</td>
        </tr>
      </table>
      <p>More formally, an evolutionary algorithm instance is a set of symbolic and numeric parameters.</p>
      <div class="ln-center">
        <p>`A_i=(S,N)`</p>
        <p>`S={text(representation), text(recombination), text(mutation), text(parent selection), text(survivor selection)}`</p>
        <p>`N={p_m, sigma, p_c, mu, lambda, k}`</p>
      </div>
      <p>where</p>
      <ul>
        <li>`p_m in [0,1]`</li>
        <li>`sigma in RR^+`</li>
        <li>`p_c in [0,1]`</li>
        <li>`mu in NN`</li>
        <li>`lambda in NN`</li>
        <li>`k in NN`</li>
      </ul>
      <p>For two instances `A_i=(S_i,N_i)` and `A_j=(S_j,N_j)`, they are considered distinct evolutionary algorithms if at least one of the symbolic parameters is different.</p>
      <div class="ln-center">
        <p>`A_i ne A_j` if `S_i ne S_j`</p>
      </div>
      <p>They are considered variants of each other if they have the same symbolic parameters but different numeric parameters.</p>
      <div class="ln-center">
        <p>`A_i ~ A_j` if `S_i = S_j` and `N_i ne N_j`</p>
      </div>
      <p>In the above example, `A_1` and `A_2` are variants of each other and `A_1` and `A_3` are distinct algorithms.</p>
      <h3>Designing Evolutionary Algorithms</h3>
      <p>Abstractly, there are three layers for an evolutionary algorithm: the design layer, the algorithm layer, and the application layer. The design layer involves choosing the parameters to create the algorithm instance. I think the algorithm layer involves defining what type of evolutionary algorithm it is, like identifying it as a genetic algorithm for example. The application layer involves running the algorithm on a real-world problem.</p>
      <p>With this, there are essentially two problems to solve: finding a solution to a real-world problem (optimization problem) and finding a set of parameters to design an algorithm to find those solutions (design problem). As a result, there are two types of quality assessments: one at the algorithm layer and one at the application layer.</p>
      <p>At the algorithm layer, we have utility and testing. Utility is the measure of an EA's performance (e.g., number of fitness evaluations, algorithm runtime). Testing is the process of calculating and comparing utilities.</p>
      <p>At the application layer, we have fitness and evaluation. Fitness is the measure of a solution's quality. Evaluation is the process of calculating and comparing fitness values.</p>
      <h3>The Tuning Problem</h3>
      <p>Parameter tuning refers to deciding what the parameters are before the algorithm is run.</p>
      <div class="ln-box">
        <p>Parameter control refers to adjusting the parameters while the algorithm is running. It can be deterministic (e.g., depending on how much time has passed), adaptive (changing based on the feedback from the search results), or self-adaptive (changing based on the quality of the solutions).</p>
      </div>
      <p>A tuner is a search algorithm that looks for the best set of parameters. In order to test a tuner's performance, we need a utility function that assigns a performance score to the tuner. Some measures that could be used for utility are mean best fitness and average number of evaluations to a solution.</p>
      <h4>Tuning by Generate-and-Test</h4>
      <p>The general flow for tuning is to generate sets of parameters and test each set. Since EAs are stochastic, the testing needs to be repeated several times. (Depending on the type of tuner -- iterative or non-iterative -- the generation of the parameters can happen once.)</p>
      <div class="ln-box">
        <p>Utility is defined formally as</p>
        <div class="ln-center">
          <p>`U(A_i)=bbb E(M(A_i,P))`</p>
        </div>
        <p>where</p>
        <ul>
          <li>`A_i` is the EA instance</li>
          <li>`P` is the problem instance</li>
          <li>`M(A_i,P))` is the performance metric (e.g., best fitness achieved, convergence speed)</li>
          <li>`bbb E` is the expected value</li>
        </ul>
        <p>Utility is estimated by the testing process.</p>
        <div class="ln-center">
          <p>`hat U(A_i)=1/n sum_(j=1)^n M(A_i^((j)),P)`</p>
        </div>
        <p>where `n` is the number of runs and `A_i^((j))` is the algorithm used on the `j^(th)` run.</p>
      </div>
      <div class="ln-box">
        <h2 id="multiobjective">Multiobjective Evolutionary Algorithms</h2>
        <p>So far, we've been dealing with problems where the goal is to optimize only one objective function. But in the real world, most problems have multiple objectives that need to be minimized or maximized. For example, when buying a car, we want to find a nice balance between price and reliability.</p>
        <p>Formally, the general multiobjective optimization problem (MOP) is defined as finding the decision variable vector</p>
        <div class="ln-center">
          <p>`bb x = [x_1, x_2, ..., x_n]^T`</p>
        </div>
        <p>that satisfies a set of constraints and optimizes a set of objective functions</p>
        <div class="ln-center">
          <p>`bb f(bb x) = [f_1(bb x), f_2(bb x), ..., f_k(bb x)]^T`</p>
        </div>
        <h3>Dominance</h3>
        <p>Suppose we have two objective functions `f_1` and `f_2`, and we want to minimize both of them. `a,b,c,d,e` are solutions.</p>
        <div class="ln-center">
          <img class="img-fluid ln-image-small" src="../pictures/ai2/moea_1.png">
        </div>
        <p>From this we can see that</p>
        <ul>
          <li>`a` is a better solution than `b` and `c`</li>
          <li>`a` is a worse solution than `e`</li>
          <li>`a` and `d` are incomparable
            <ul>
              <li>`a` is better than `d` in terms of `f_1`, but `d` is better than `a` in terms of `f_2`</li>
            </ul>
          </li>
        </ul>
        <p>This introduces the concept of dominance. We say that `a` dominates `b` and `c`, and `e` dominates `a`.</p>
        <p>Formally, a solution `x` dominates a solution `y` if</p>
        <ul>
          <li>`x` is better than `y` in at least one objective</li>
          <li>`x` is not worse than `y` in all other objectives</li>
        </ul>
        <p>`x` dominates `y` is written as</p>
        <div class="ln-center">
          <p>`x preceq y` for minimization</p>
          <p>`x succeq y` for maximization</p>
        </div>
        <p>This is generally what it looks like for the minimization case:</p>
        <div class="ln-center">
          <img class="img-fluid ln-image-small" src="../pictures/ai2/dominance.png">
        </div>
        <h3>Pareto Optimality</h3>
        <p>It's rare (at least I imagine it is) for there to exist one solution that optimizes all objective functions. More likely, there will be a set of solutions that are all fairly good, but they each have their own benefits and tradeoffs. These are referred to as Pareto optimal solutions.</p>
        <p>In the example below, the green solutions are the Pareto optimal solutions. They're better than all the other solutions, but each Pareto optimal solution is not definitively better than any other Pareto optimal solution.</p>
        <div class="ln-center">
          <img class="img-fluid ln-image-small" src="../pictures/ai2/pareto_optimal.png">
        </div>
        <p>Formally, a solution `x` is non-dominated if no solution dominates `x`. A set of non-dominated solutions is the Pareto optimal set. The image (in the context of functions) of the Pareto optimal set is the Pareto optimal front.</p>
        <div class="ln-center">
          <img class="img-fluid ln-image-small" src="../pictures/ai2/pareto_optimal_2.png">
        </div>
        <p>The set of Pareto optimal solutions is defined as</p>
        <div class="ln-center">
          <p>`cc P^(ast) = {x in Omega | not EE x' in Omega text( ) f(x') preceq f(x)}`</p>
          <p>(there does not exist a solution that dominates a Pareto optimal solution)</p>
        </div>
        <p>The Pareto front is defined as</p>
        <div class="ln-center">
          <p>`cc P cc F^(ast) = {(f_1(x), ..., f_k(x)) | x in cc P^(ast)}`</p>
        </div>
        <h3>Solving Multiobjective Problems</h3>
        <h4>NSGA II</h4>
        <p>NSGA stands for Nondominated Sorting Genetic Algorithm. It is an algorithm that can find multiple Pareto optimal solutions in a single simulation run. It works by classifying individuals into layers based on dominance. For individuals that are in the same layer, the solution that is in the lesser crowded region is considered better.</p>
        <h4>MOEA/D</h4>
        <p>MOEA/D stands for Multiobjective Evolutionary Algorithm Based on Decomposition. It decomposes the optimization problem into `n` scalar optimization subproblems, which are solved in parallel.</p>
      </div>
      <h2 id="llm">LLMs</h2>
      <p>Generative AI is a type of AI that creates new content based on what it has learned from existing content. One example of a generative model is a large language model (LLM). At its core, LLMs are word predictors, that is, they generate text by predicting what words should be used.</p>
      <p>For example, suppose we have the sentence, "When I hear rain on my roof, I _ in my kitchen." Using the surrounding words for context, an LLM makes predictions for what word(s) should go in the blank by assigning probabilties to word(s) that the LLM has seen in similar contexts. Some choices could be</p>
      <ul>
        <li>cook soup (`9.4%`)</li>
        <li>warm up a kettle (`5.2%`)</li>
        <li>nap (`3.6%`)</li>
        <li>relax (`2.5%`)</li>
      </ul>
      <p>So how does predicting text relate to generating text? LLMs generate text by repeatedly predicting what word it thinks should come next after its own prediction.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/ai2/llm.gif">
      </div>
      <div class="ln-box">
        <p>This is similar to how training is done for the LLM. The current group of words is the input and the target is the next word that comes next.</p>
        <div class="ln-center">
          <img class="img-fluid ln-image-small" src="../pictures/ai2/llm_2.gif">
        </div>
      </div>
      <div class="ln-box">
        <p>The first step in creating an LLM is to pretrain it on a large amount of text data. It's like literally feeding it a bunch of words so that it can develop a vocabulary.</p>
        <p>The second step is to train it on a large amount of text data, except this time, the data is labeled. For example, we could give the LLM a bunch of sentences related to finance so that it learns what types of words are associated with finance. This type of training is called classification fine-tuning. There is another type of training called instruction fine-tuning where we give the LLM instructions (prompts) and sample answers so that it learns how certain questions/commands should be responded to.</p>
        <p>After the first pretraining step, we end up with a foundation model that already has some basic capabilities, like text completion and typo recognition/correction. The second step is how we get more advanced LLMs.</p>
      </div>
      <h3>Embeddings</h3>
      <p>LLMs don't actually understand words and text. They're like computers; they work with numbers. Words are converted into numbers, which the LLM performs calculations on to produce more numbers, which are converted back into words. The process of converting words into numbers is called embedding.</p>
      <p>The basic idea behind embeddings is that words are assigned numerical values based on certain qualities or meanings of the word. So similar words, like words about finance, have similar numerical values.</p>
      <div class="ln-box">
        <p>More specifically, words are converted into continuous-valued vectors.</p>
        <div class="ln-center">
          <p>This `rarr [[-2.7], [-2.3], [8.9]]`</p>
          <p>is `rarr [[-4.7], [-0.5], [6.2]]`</p>
          <p>an `rarr [[6.2], [5.0], [-4.2]]`</p>
          <p>example `rarr [[-0.1], [4.3], [-6.2]]`</p>
        </div>
      </div>
      <h3>Tokenizing</h3>
      <p>In order to create word embeddings, the text has to be split into individual tokens. A token can be thought of as an individual word.</p>
      <p>For example, the sentence, "This is an example." can be tokenized into four tokens:</p>
      <div class="ln-center">
        <p>["This", "is", "an", "example."]</p>
      </div>
      <p>So a simple strategy for tokenizing a sentence is to split the sentence on spaces.</p>
      <div class="ln-box">
        <p>If we wanted to remove or tokenize punctuation, we could use regular expressions.</p>
      </div>
      <p>Once we have our tokens, we convert each token into a token ID. A simple way of doing this is to do</p>
      <div class="ln-center">
        <p>This `rarr 0`<br>is `rarr 1`<br>an `rarr 2`<br>example `rarr 3`</p>
      </div>
      <div class="ln-box">
        <p>Let's say we wanted to build an LLM that can recognize phrases from books. To train it, we would give it a bunch of books to read. Programmatically, I suppose we would probably combine all the books into one large text file and feed that to the LLM. In order to know which text belongs to which book, we would need some sort of marker to indicate where one book ends and the next book begins. During the tokenization process, we use a special context token (e.g., &lt;|endoftext|&gt;) to handle this situation. Special context tokens also get converted into token IDs.</p>
      </div>
      <div class="ln-box">
        <p>Another type of special context token is &lt;|unk|&gt; for handling unknown words (unknown to the LLM)</p>
      </div>
      <h3>Now, (Back) to Embeddings</h3>
      <div class="ln-box">
        <p>For simplicity, I'll continue with the assumption that a token is a word. So I'll use "token" and "word" interchangeably.</p>
      </div>
      <p>Each word in the LLM's vocabulary is initially assigned a vector of random values. These vectors form what is called the embedding matrix. A word's embedding vector is obtained by using the token ID to "index" into the embedding matrix.</p>
      <div class="ln-center">
        <p>`[[text(This)], [text(is)], [text(an)], [text(example)]] rarr [[-2.7, -2.3, 8.9], [-4.7, -0.5, 6.2], [6.2, 5.0, -4.2], [-0.1, 4.3, -6.2]]`</p>
      </div>
      <p>These random values get updated during the training process as the LLM learns more about what each word means.</p>
      <div class="ln-box">
        <p>One small thing that is missing so far is that an embedding needs to encode information about the position of a word in a sentence. The two sentences "The dog chased the cat." and "The cat chased the dog." are very different, even though they have the exact same words.</p>
        <p>There are two ways to inject position information into a word's embedding. We could add the token's exact position (e.g., `2.0` for the second token) to the embedding vector. This is absolute positional embedding. The other way is to include information about distance or relative order between tokens (e.g., "token A is 3 positions after token B"). This is relative positional embedding.</p>
      </div>
      <h3>Attention</h3>
      <p>What are some words that can follow the word "too"? This question is hard to answer because there are a billion options and we don't know what the context is. We can see that in order to predict words, we need to know the information that came before.</p>
      <p>Now consider the following sentence: "The chicken didn't cross the road because it was too _". What could the next word be? It's easier to narrow down the options, but there are still many options, because it depends on what "it" is referring to. Is "it" referring to the chicken or the road?</p>
      <p>"The chicken didn't cross the road because it was too tired." In this sentence, "it" is referring to the chicken. We can say that the word 'it' "attends to" the word 'chicken'. "The chicken didn't cross the road because it was too wide." In this sentence, "it" is referring to the road. We can say that the word 'it' "attends to" the word 'road'.</p>
      <p>This leads into the concept of attention. Attention is the process of updating a word's meaning based on the other words that exist in the context.</p>
      <div class="ln-box">
        <p>More specifically, we'll look at self-attention, which is a type of attention mechanism. The "self" is referring to the fact that we're looking at how different parts of the input relates to itself (in this case, how each word in a sentence relates to each other).</p>
      </div>
      <p>The idea is that a word's embedding vector gets updated by all of the other embedding vectors. Looking at the words "chicken", "road", "it", and "wide", let's say we wanted to update the embedding vector for "it" using self-attention.</p>
      <div class="ln-center">
        <p>it `rarr [[0.4], [0.1], [0.8]]`</p>
        <p>`darr`</p>
        <p>how important is the word "chicken" to the word "it"?</p>
        <p>`darr`</p>
        <p>it `rarr [[0.5], [0.8], [0.6]]`</p>
        <p>`darr`</p>
        <p>how important is the word "road" to the word "it"?</p>
        <p>`darr`</p>
        <p>it `rarr [[0.2], [0.5], [0.3]]`</p>
        <p>`darr`</p>
        <p>how important is the word "it" to the word "it"?</p>
        <p>`darr`</p>
        <p>it `rarr [[0.8], [0.3], [0.1]]`</p>
        <p>`darr`</p>
        <p>how important is the word "wide" to the word "it"?</p>
        <p>`darr`</p>
        <p>it `rarr [[0.5], [0.9], [0.3]]`</p>
      </div>
      <p>The end result is that we have a new embedding vector for the word "it" that captures the relationships between the word "it" and all the other words.</p>
      <p>The information about how important a word is to another word is measured by an "attention weight". So how do we get this information?</p>
      <h4>Simple Self-Attention</h4>
      <p>One way is to calculate the dot product of a word's embedding vector with another word's embedding vector.</p>
      <div class="ln-box">
        <p>If two vectors are pointing in the same direction, then their dot product will be large. In the context of word embeddings, if two vectors are pointing in the same direction, then the two words are strongly related to each other.</p>
        <p>If two vectors are pointing in different directions, then their dot product will be small. In the context of word embeddings, if two vectors are pointing in different directions, then the two words are not really related to each other.</p>
      </div>
      <p>The dot product gives us an attention score. Once we have calculated all the attention scores for a word, we normalize them to get attention weights.</p>
      <div class="ln-box">
        <p>This process of normalization is needed so we can know how much more important one word is vs. another word.</p>
        <p>A simple way to normalize the attention scores is to divide by the `1`-norm.</p>
        <div class="ln-center">
          <p>`bb alpha = bb omega/norm(bb omega)_1`</p>
        </div>
        <p>where `bb omega` is a vector of attention scores and `bb alpha` is the resulting vector of attention weights.</p>
        <p>The more common way to normalize is to use the softmax function.</p>
        <div class="ln-center">
          <p>`alpha_i = e^(omega_i)/(sum_(j=1)^K e^(omega_j))`</p>
        </div>
      </div>
      <p>Going back to the sentence "The chicken didn't cross the road because it was too wide", the process for updating the embedding vector for "it" looks like:</p>
      <div class="ln-center">
        <p>`[[0.0], [0.8], [0.5]] * alpha_(8__1) + [[0.2], [0.3], [0.4]] * alpha_(8__2) + ... + [[0.1], [0.2], [0.7]] * alpha_(8__11)`</p>
        <p>(embedding vector for "The") `xx` (attention weight for the eighth word and the first word)</p>
        <p>`+`</p>
        <p>(embedding vector for "chicken") `xx` (attention weight for the eighth word and the second word)</p>
        <p>`+`</p>
        <p>`vdots`</p>
        <p>`+`</p>
        <p>(embedding vector for "wide") `xx` (attention weight for the eighth word and the eleventh word)</p>
      </div>
    </div>
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-HwwvtgBNo3bZJJLYd8oVXjrBZt8cqVSpeBNS5n7C8IVInixGAoxmnlMuBnhbgrkm" crossorigin="anonymous"></script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
  </body>
</html>
