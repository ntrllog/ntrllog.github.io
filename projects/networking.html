<!DOCTYPE html>
<html lang="en">
  <head>
    <!--
                                      _
        /\     _             _   _   | |             __    __
       /  \   | |      /\   | \ | |  | |       /\   |  \  /  |
      /    \  | |     /  \  |  \| |  | |      /  \  | |\\//| |
     / ____ \ | |__  / __ \ | |\  |  | |___  / __ \ | | \/ | |
    /_/    \_\|____|/_/  \_\|_| \_|  |_____|/_/  \_\|_|    |_|
                          _   _
     _  _    _     _  _  | | | |   __     ____
    | |/ \  | |_  | |/_| | | | |  /  \   /    \
    | |   | |  _| |  /   | | | | | || | |  ||  |
    | |   | | |_  | |    | | | | | || | |  ||  |
    |_|   | |___| |_|    |_| |_|  \__/   \____/|
                                               |
                                          ____/
    -->
    <title>ntrllog | Computer Networking</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet">
    <link rel="shortcut icon" type="image/png" href="../pictures/favicon.ico"/>
    <link href="../css/content.css" rel="stylesheet">
  </head>
  <body>
    <div class="dropdown ln-fixed-right">
      <button class="btn btn-secondary dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false">ToC</button>
      <ul class="dropdown-menu">
        <li><a class="dropdown-item" href="#whatisit">What is the Internet?</a></li>
        <li><a class="dropdown-item" href="#networkedge">Livin' on the Edge</a></li>
        <li><a class="dropdown-item" href="#networkcore">The Network Core</a></li>
        <li><a class="dropdown-item" href="#delay">Delay, Loss, and Throughput</a></li>
        <li><a class="dropdown-item" href="#protocollayers">Protocol Layers</a></li>
        <li><a class="dropdown-item" href="#networkapplications">Principles of Network Applications</a></li>
        <li><a class="dropdown-item" href="#http">The Web and HTTP</a></li>
      </ul>
    </div>
    <div class="container ln-line-height">
      <a href="projects.html"><i class="fas fa-long-arrow-alt-left fa-2x"></i></a>
      <h1>Computer Networking</h1>
      <hr>
      <p>Shortcut to this page: <a href="networking.html">ntrllog.netlify.app/networking</a></p>
      <p>Info provided by <a href="https://gaia.cs.umass.edu/kurose_ross/index.php" target="_blank">Computer Networking: A Top-Down Approach</a> and Professor Senhua Yu.</p>
      <h2 id="whatisit">What is the Internet?</h2>
      <p>Computers. Laptops. Smartphones. TVs. Watches. And everything else that has the word "smart" in front of it. All of these things that can connect to the Internet are called <b>hosts</b> or <b>end systems</b>. End systems send and receive data through a system of communcation links and packet switches. The data travels through this system as little pieces called packets and they are reassembled when they reach their destination. Packet switches are machines that help transfer these packets. The whole path that a packet takes is called a <b>route</b> or <b>path</b>.</p>
      <div class="ln-box">
        <p>A <b>router</b> is a type of packet switch. Yes, the router that connects to the modem.</p>
      </div>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/nuts_and_bolts.png">
      </div>
      <div class="ln-box">
        <p>I believe the shape I'll be using for all packet switches is a circle/oval. And links will be just a line connecting the circles.</p>
      </div>
      <p>Access to the Internet is provided by <b>Internet Service Providers</b> (<b>ISPs</b>). Think ATT and Spectrum for example. ISPs themselves are a network of packet switches and communication links.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-smaller" src="../pictures/networking/isp.png">
      </div>
      <h3>What is a Protocol?</h3>
      <p>All the devices involved with sending and receiving packets run <b>protocols</b>, which are a set of rules defining:</p>
      <ul>
        <li>how messages should be formatted</li>
        <li>the order of the messages exchanged</li>
        <li>the actions that can be performed when the messages are received or transmitted</li>
      </ul>
      <p>The protocols are defined by <b>Internet standards</b>, which are developed by the Internet Engineering Task Force (IETF). The actual documents are called <b>requests for comments</b> (<b>RFCs</b>).</p>
      <div class="ln-box">
        <p>When we go to a URL on our browser, the actions that occur are a result of following a protocol (the TCP protocol).</p>
        <ol>
          <li>Computer sends a request to connect to the Web server and waits for a reply</li>
          <li>Web server receives the connection request and returns a "connection okay" message</li>
          <li>Computer sends the name of the Web page we want</li>
          <li>Web server sends it to our computer</li>
        </ol>
      </div>
      <h2 id="networkedge">Livin' on the Edge</h2>
      <p>The word "end system" is used to describe devices that connect to the Internet because they exist at the "edge" of the Internet.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-smaller" src="../pictures/networking/network_edge.png">
      </div>
      <h3>Access Networks</h3>
      <p>The access network is the network where end systems connect to the first router in the path to the ISP. (There may be many routers in between the ISP and a home. The first router is the one that's actually in the home.) Basically, an access network is a network on the edge of the Internet.</p>
      <h4>Home Access: What's the WiFi Password?</h4>
      <p>The home network will probably be the easiest for everyone to relate to. All our phones, laptops, tablets, computers, and everything else that connect to the WiFi in our homes form a home network.</p>
      <p>Two of the most popular ways to get Internet access are by a <b>digital subscriber line</b> (<b>DSL</b>) (think telephone lines and telephone companies) and cable.</p>
      <h4>Wide-Area Wireless Access: Unlimited Talk, Text, and Web For Only $ Per Month!</h4>
      <p>When our phones aren't connected to WiFi, it uses mobile data, which is Internet provided by cellular network providers through base stations (cell towers?). This is where the terms 3G, 4G, 5G, and LTE come into play. (6G doesn't exist yet at the time of this writing.)</p>
      <h2 id="networkcore">The Network Core</h2>
      <p>The network core is, well, the part of the Internet that is not at the edge. This is the part of the Internet that our router connects to — out to where our Internet access comes from.</p>
      <h3>Packet Switching</h3>
      <p>The data that the end systems send and receive are called <b>messages</b>. Messages can be any type of data, such as emails, pictures, or audio files. When going from its source to its destination, messages are broken up into packets, which are transferred from packet switch to packet switch. From packet switch to packet switch, each packet is broken up into bits and sent across the communication link connecting the two packet switches.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-smaller" src="../pictures/networking/packet_switching.png">
      </div>
      <h4>No Packet Left Behind</h4>
      <p>Most packet switches use <b>store-and-forward transmission</b>. This means that the packet switch waits until it receives the entire packet before it starts sending the first bit of the packet to the next location.</p>
      <div class="ln-box">
        <p>Consider a simple network of two end systems and one packet switch. The source has three packets to send to the destination.</p>
        <div class="ln-center">
          <img class="img-fluid ln-image-small" src="../pictures/networking/packet_switching_2.png">
        </div>
        <p>Let's say each packet has `L` bits and that each communication link can transfer `R` bits per second. Then the total time it takes to transfer one packet across one communication link is `L/R` seconds.</p>
        <p>So the time it takes to transfer the packet from source to destination is `2L/R`.</p>
        <div class="ln-center">
          <img class="img-fluid ln-image-small" src="../pictures/networking/packet_switching_3.png">
        </div>
        <p>How long does it take to transfer all three packets from source to destination? At `L/R` seconds, the packet switch receives all of the first packet. At this time, while the packet switch starts sending bits of the first packet to the destination, it also starts receiving bits of the second packet from the source.</p>
        <p>At `2L/R` seconds, the first packet arrives at the destination and the second packet arrives at the packet switch.</p>
        <p>At `3L/R` seconds, the second packet arrives at the destination and the third packet arrives at the packet switch.</p>
        <p>At `4L/R` seconds, the third packet arrives at the destination.</p>
        <div class="ln-center">
          <img class="img-fluid ln-image-small" src="../pictures/networking/packet_switching.gif">
        </div>
        <p>Let's generalize this for `N` communication links and `P` packets.</p>
        <p>Since the time it takes for one packet to travel across one communication link is `L/R`, it takes one packet `NL/R` time to travel across `N` communication links.</p>
        <p>At time `NL/R`, the first packet will reach the destination. If there are `P` packets in total, then there will be `P-1` more times where there is a packet sitting in the last packet switch (i.e., there will be `P-1` more packets passing through the last packet switch). Since it takes `L/R` time to go from the last packet switch to the destination, it will take `(P-1)L/R` time for all the packets to reach the destination. So the total time it takes `P` packets to travel across `N` communication links is `NL/R+(P-1)L/R=(N+P-1)L/R`.</p>
      </div>
      <div class="ln-box">
        <p>Besides store-and-forward, there's also cut-through switching, in which the switch starts sending bits before the whole packet is received.</p>
      </div>
      <h4>Queuing Delays</h4>
      <p>Realistically, a packet switch has more than two links. For each link in the packet switch, there is an <b>output buffer</b> (a.k.a. <b>output queue</b>) where the packets wait if the link is busy. This can happen if the transmission rate of the link is slower than the arrival rate of the packets, i.e., the packets are coming in faster than the packet switch can send them out.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/output_buffer.png">
      </div>
      <h4>Okay, Some Packets Left Behind</h4>
      <p>Since the buffer can only be so big, if there isn't enough room for more incoming packets, some packets will be dropped, resulting in <b>packet loss</b>. Depending on the implementation, either the arriving packet or one of the packets in the buffer is dropped.</p>
      <h4>Forwarding Tables</h4>
      <p>Again, packet switches usually have multiple links. So how does the packet switch know which link to use to send the packet? The answer is that each packet switch has a <b>forwarding table</b> that lists the destination of each link. When a packet arrives, the packet switch examines the packet to see its destination and searches it up in its forwarding table. The table tells the packet switch which link to use to get to the destination.</p>
      <h3>Circuit Switching</h3>
      <p>With packet switching, the packets are sent and if there is a lot of traffic, then oh well. Maybe the data will take a long time to send, or worse, get dropped. To avoid this, we can reserve the resources ahead of time.</p>
      <p>With circuit switching, each link has a number of circuits. One circuit per link is required for communication between two end systems. So a link with, for example, four circuits can support four different connections at the same time. However, each connection only gets a fraction of the link's transmission rate.</p>
      <div class="ln-box">
        <p>Suppose we have a link with four circuits and a transmission rate of `1` Mbps. Then each circuit can only transfer data at a rate of `1/4` Mbps, which is `250` kbps.</p>
      </div>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/circuit_switching.png">
      </div>
      <h4>Frequency-Division Multiplexing</h4>
      <p>Multiplexing is sending multiple signals as one big signal.</p>
      <p>Multiple end systems can all use one link to transfer data if there are enough circuits. Each end system will be transferring different data, but they all get transferred over as "one big data" through the link. The way to differentiate which data came from which end system is to divide the link into different frequencies, like the example above.</p>
      <div class="ln-box">
        <p>Radio uses FDM. We can tune in to a specific frequency to listen to the station we want.</p>
      </div>
      <h4>Time-Division Multiplexing</h4>
      <p>With time-division multiplexing, the end systems get to use all of the frequency to transfer data, but only for a limited amount of time.</p>
      <div class="ln-box">
        <p>Suppose there are two end systems (`A` and `B`) communicating with two other end systems using the same link. Let's say they're only allowed `1`-second intervals to send their data. So from `0` to `1` seconds, part of the data from `A` and part of the data from `B` gets sent. From `1` to `2` seconds, part of the data from `A` and part of the data from `B` gets sent. And this repeats for every second.</p>
        <div class="ln-center">
          <img class="img-fluid ln-image-small" src="../pictures/networking/tdm.png">
        </div>
      </div>
      <div class="ln-box">
        <p>More formally, time is divided into frames, and each frame is divided into slots. Once a connection between two end systems is established, one slot in every frame is reserved just for that connection.</p>
        <div class="ln-center">
          <img class="img-fluid ln-image-small" src="../pictures/networking/tdm_2.png">
        </div>
      </div>
      <div class="ln-box">
        <p>Suppose that all links in a network use TDM with `24` slots and can transfer data at a rate of `1.536` Mbps. Then each circuit has a transmission rate of `1.536/24=64` kbps.</p>
      </div>
      <h4>Switching Teams</h4>
      <p>Packet switching is not good for things that require a continuous connection, like video calls. However, packet switching is, in general, more efficient than circuit switching.</p>
      <div class="ln-box">
        <p>Suppose several users share a `1` Mbps link. But each user is not using the connection all of the time, i.e., there are periods of activity and inactivity. Let's say that a user is actively using the connection 10% of the time, and generates data at `100` kbps when they are active. With circuit switching, this means the link can support `(1 text( Mbps))/(100 text( kbps))=10` users at once. The circuit must be reserved for all `10` users as long as they are connected, even if they're not using it all the time.</p>
        <p>With packet switching, resources are not reserved, so any number of users can use the link. If there are `35` users, the probability that `ge 11` users are actively using the connection at the same time is ~`0.0004`, which means there is a ~`0.9996` chance that there are `le 10` simultaneous users at any time. As long as there are not more than `10` users at a time, there will be no queuing delay (if there are more than `10` users, there will be more data than the `1` Mbps link can handle). So packet switching performs just as well as circuit switching while allowing for more users at the same time.</p>
      </div>
      <div class="ln-box">
        <p>Sticking with the same `1` Mbps link, suppose there are `10` users. One of the users suddenly generates `1,000,000` bits of data, but the other users are inactive. Suppose the link has `10` slots per frame. If all `10` slots are utilized, then the link can send `1,000,000` bits per second (`= 1` Mbps). However, under the rules of circuit switching, only one of the slots per frame will be used for that user. So the link will only be able to transfer `(1,000,000)/10=100,000` bits per second. So it will take `(1,000,000)/(100,000)=10` seconds to transfer all the data.</p>
        <p>With packet switching, since no other users are active, the one user gets to send all `1,000,000` bits of data in `1` second since there will be no queuing delays.</p>
      </div>
      <h3>A Network of Networks</h3>
      <p>We get our Internet access from an ISP. Of course, all of us don't get Internet access from the same ISP. There are different ISPs out there providing Internet access to different networks. But then how do our end systems communicate with end systems? How do we communicate with servers and access websites from different parts of the world for example? The answer is that the ISPs themselves are connected with each other. But what exactly does that look like?</p>
      <p>One idea is that we connect every ISP with each other directly.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/isp_structure_1.png">
      </div>
      <p>The problem with this is that it is too costly, because there would be way too many links. In computer science terms, there would be `n^2` connections.</p>
      <p>To minimize the number of connections, another idea is that there is a global ISP and all the other ISPs connect to that global one.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/isp_structure_2.png">
      </div>
      <p>This, too, is costly. But to offset the cost, the global ISP would charge the other ISPs (we'll call them access ISPs from this point on) money to connect to the global ISP.</p>
      <p>But if one global ISP becomes profitable, naturally there will be other global ISPs wishing to be profitable too.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/isp_structure_3.png">
      </div>
      <p>This structure is good for the access ISPs because they can choose which global ISP they want to connect to by comparing prices and service quality. So what we have so far is a two-tier hierarchy where global ISPs are at the top and access ISPs are at the bottom.</p>
      <p>The reality is that these global ISPs can't exist in every city in the world. What happens instead is that the access ISPs connect to a <b>regional ISP</b>, which then connects to a global ISP. (We'll now be calling global ISPs by the more correct term <b>tier-1 ISP</b>.) Some examples of tier-1 ISPs are AT&amp;T, Verizon, and T-Mobile.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/isp_structure_4.png">
      </div>
      <div class="ln-box">
        <p>Sometimes, an access ISP can connect directly to a tier-1 ISP. In that case, the access ISP would pay the tier-1 ISP.</p>
      </div>
      <div class="ln-box">
        <p>In some regions, there can be a larger regional ISP consisting of smaller regional ISPs.</p>
      </div>
      <div class="ln-box">
        <p>Access ISPs and regional ISPs can choose to <b>multi-home</b>. That is, they can connect to more than one provider ISP at the same time, getting Internet access from multiple ISPs. While they have to pay each ISP they're connected to, the multi-homed ISPs can achieve better reliability in case one of the provider ISPs has a failure.</p>
      </div>
      <p>This multi-tier hierarchy is closer to the structure of today's Internet, but there are still a few pieces missing.</p>
      <p>Lower-tier ISPs pay higher-tier ISPs based on how much traffic goes through their connection. To avoid sending traffic to the higher-tier ISPs, the lower-tier ISPs can <b>peer</b>. This means that they connect with each other so that the traffic goes between them instead of up to the higher-tier ISP.</p>
      <p>For example, suppose that a computer connected to the green ISP wants to communicate with a computer connected to the blue ISP. Without peering, the traffic would have to go all the way up to the tier-1 ISP and back down from there.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/isp_structure_5.png">
      </div>
      <p>But with peering, they can avoid the cost of going through the regional and tier-1 ISPs by connecting with each other directly. Usually when ISPs peer with each other, they agree to not pay each other for the traffic that comes from peering.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/isp_structure_6.png">
      </div>
      <p>To facilitate this peering, third-party companies can create an <b>Internet Exchange Point</b> (<b>IXP</b>) which ISPs connect to to peer with other ISPs.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/isp_structure_7.png">
      </div>
      <p>There's one more piece: <b>content-provider networks</b>. Content providers are companies like Google, Amazon, and Microsoft.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/isp_structure_8.png">
      </div>
      <p>They run their own private networks so that they can bring their services and content closer to users. They do this by having data centers distributed everywhere across the world. Each data center has tons of servers that are all connected to each other.</p>
      <p>And this is why the Internet is a network of networks. (Recall that ISPs themselves are networks of packet switches and links. There's also the edge network from the previous section, and each network in the edge network is a network of routers and links.)</p>
      <h2 id="delay">Delay, Loss, and Throughput</h2>
      <p>In a (developer's) perfect world, data would travel through the Internet instantaneously without any limitations. Well, we know things aren't perfect.</p>
      <h3>What's the Holdup?</h3>
      <p>As packets travel along their route, they experience <b>nodal processing delay</b>, <b>queuing delay</b>, <b>transmission delay</b>, and <b>propagation delay</b>. All these delays combined is called <b>total nodal delay</b>.</p>
      <h4>Processing Delay</h4>
      <p>When a packet arrives at a router, the router looks at the packet's header to see which link it should go on. It also checks for any bit-level errors in the packet. The time it takes to do this (microseconds), is the <b>processing delay</b>.</p>
      <h4>Queuing Delay</h4>
      <p>Once the outbound link has been determined, the packet goes to the queue for that link. The time it waits in the queue (microseconds to milliseconds), is the <b>queuing delay</b>.</p>
      <h4>Transmission Delay</h4>
      <p>Once the packet reaches the front of the queue, it is ready to be transferred across the link. Recall that packets travel through links as bits. The time it takes to push all of the bits into the link (microseconds to milliseconds) is the <b>transmission delay</b>. If a packet has `L` bits and the link can transfer `R` bits per second, then the transmission delay is `L/R`.</p>
      <h4>Propagation Delay</h4>
      <p>Now that the bits are on the link, they must get to the other end. The time it takes to get from the beginning of the link to the end of the link (milliseconds) is the <b>propagation delay</b>. This is determined by two things: how fast the bits are able to move and how far they have to go. How fast the bits can move depends on the physical characteristics of the link (e.g., whether it's fiber optics or twisted-pair copper wire) and is somewhere near the speed of light.</p>
      <p>If `d` is the distance the bit has to travel, i.e., the length of the link, and `s` is the propagation speed of the link, then `d/s` is the propagation delay.</p>
      <div class="ln-box">
        <p>Transmission delay and propagation delay sound very similar to each other. So here are some pictures illustrating the difference.</p>
        <div class="ln-center">
          <img class="img-fluid ln-image-smaller" src="../pictures/networking/transmission_delay.png">
        </div>
        <div class="ln-center">
          <img class="img-fluid ln-image-smaller" src="../pictures/networking/propagation_delay.png">
        </div>
        <p>Yeah, somehow the bits go from being on a conveyer belt to being pushed in needlessly large carts. There's no delay from belt to cart though. That part happens magically.</p>
      </div>
      <div class="ln-box">
        <p>Consider a packet of length `L` which begins at end system `A` and travels over three links to a destination end system. These three links are connected by two packet switches. For `i=1,2,3`, let `d_i`, be the length of each link, `s_i` be the propagation speed of each link, and `R_i` be the transmission rate of each link. The packet switch delays each packet by `d_text(proc)`. Assume there are no queuing delays.</p>
        <p>In terms of `d_i`, `s_i`, `R_i`, and `L`, what is the total end-to-end delay for the packet?</p>
        <div class="collapse ln-box" id="delay_q1">
          <p>The total end-to-end delay is the sum of all the delays: processing delay, queuing delay, transmission delay, and propagation delay.</p>
          <p>The processing delay is given to us as `d_text(proc)`. There are two packet switches, so there will be two processing delays.</p>
          <p>We are also given that there are no queuing delays.</p>
          <p>The transmission delay is `L/R_1+L/R_2+L/R_3`.</p>
          <p>The propagation delay is `d_1/s_1+d_2/s_2+d_3/s_3`.</p>
          <p>So the total end-to-end delay is `d_text(proc)+d_text(proc)+L/R_1+L/R_2+L/R_3+d_1/s_1+d_2/s_2+d_3/s_3`.</p>
        </div>
        <button class="btn" type="button" data-bs-toggle="collapse" data-bs-target="#delay_q1" aria-expanded="false" aria-controls="delay_q1">Answer</button>
        <p>Suppose now the packet is `1500` bytes, the propagation speed on all three links is `2.5*10^8` m/s, the transmission rates of all three links are `2` Mbps, the packet switch processing delay is `3` ms, the length of the first link is `5000` km, the length of the second link is `4000` km, and the length of the third link is `1000` km. What is the end-to-end delay?</p>
        <div class="collapse ln-box" id="delay_q2">
          <p>From the first question, we know that the end-to-end delay is `d_text(proc)+d_text(proc)+L/R_1+L/R_2+L/R_3+d_1/s_1+d_2/s_2+d_3/s_3`, so now we'll just calculate and plug in those values.</p>
          <p>We're given that `d_text(proc)=3` ms.</p>
          <p>To calculate transmission delay, we'll first convert everything to bits. There are `8` bits in a byte, so the packet length is `1500*8=12,000` bits. For the transmission rate, `2` Mbps = `2,000,000` bits per second. Since all three links have the same transmission rate, `R_1=R_2=R_3`. So `L/R_1=L/R_2=L/R_3=(12,000)/(2,000,000)=0.006` seconds `=6` ms.</p>
          <p>For the propagation delay, we'll first convert everything to meters. The lengths of the links are `5,000,000` m, `4,000,000` m, and `1,000,000` m. Since all three links have the same propagation speed, `s_1=s_2=s_3`. So `d_1/s_1=(5,000,000)/(250,000,000)=0.02` seconds `=20` ms, `d_2/s_2=(4,000,000)/(250,000,000)=0.016` seconds `=16` ms, and `d_3/s_3=(1,000,000)/(250,000,000)=0.004` seconds `=4` ms.</p>
          <p>So the total-end-to-end delay is `3+3+6+6+6+20+16+4=64` ms.</p>
        </div>
        <button class="btn" type="button" data-bs-toggle="collapse" data-bs-target="#delay_q2" aria-expanded="false" aria-controls="delay_q2">Answer</button>
      </div>
      <div class="ln-box">
        <p>Consider a highway that has a tollbooth every `100` km. It takes `12` seconds for a tollbooth to service a car. Suppose a caravan of `10` cars are on the highway with each car traveling `100` km/hour. When going from tollbooth to tollbooth, the first car waits at the tollbooth until the the other nine cars arrive. To analogize, the tollbooth is a router, the highway is a link, the cars are bits, and the caravan is a packet.</p>
        <p>How long does it take the caravan to travel from one tollbooth to the next?</p>
        <div class="collapse ln-box" id="caravan_q1">
          <p>Since the tollbooth takes `12` seconds to service a car and there are `10` cars, it takes a total of `120` seconds (or `2` minutes) to service all the cars.</p>
          <p>Since the distance between every tollbooth is `100` km and the cars are moving at `100` km/hour, it takes `1` hour (or `60` minutes) to reach the next tollbooth.</p>
          <p>Since the cars in the caravan travel together, everything depends on the last car. So we'll look at this from the last car's point of view.</p>
          <p>The last car has to wait `2` minutes before it can be serviced by the tollbooth. Once this is done, it takes `60` minutes for it to reach the next tollbooth. So it takes the last car `62` minutes to reach the next tollbooth.</p>
          <p>Here's some animation to visualize:</p>
          <div class="ln-center">
            <img class="img-fluid ln-image-small" src="../pictures/networking/caravan.gif">
          </div>
          <p>At `120` seconds all `10` cars have exited the first tollbooth and are on the highway to the next tollbooth.</p>
          <p>The first car will take `60` minutes to enter the next tollbooth (get off the animation line), but since it waited `12` seconds for the previous tollbooth servicing, it will enter the next tollbooth at `60:12`.</p>
          <div class="ln-center">
            <img class="img-fluid ln-image-small" src="../pictures/networking/caravan_2.gif">
          </div>
        </div>
        <button class="btn" type="button" data-bs-toggle="collapse" data-bs-target="#caravan_q1" aria-expanded="false" aria-controls="caravan_q1">Answer</button>
        <p>To analogize some more, the time it takes the tollbooth to service a car is the transmission delay. The time it takes the car to move to the next tollbooth is the propagation delay.</p>
        <p>Now suppose that the cars travel at `1000` km/hour and the tollbooth takes `1` minute to service a car. Will cars arrive at the second tollbooth before all the cars are serviced at the first tollbooth? That is, will there still be cars at the first tollbooth when the first car arrives at the second tollbooth?</p>
        <div class="collapse ln-box" id="caravan_q2">
          <p>Now it takes `10` minutes to service all `10` cars.</p>
          <p>The first car will wait `1` minute for the tollbooth to service it. Then it will take `6` minutes (`(100text(km))/((1000text(km))/(60text(min)))=6`) to reach the next tollbooth. So it will take a total of `7` minutes for the first car to go from one tollbooth to the next.</p>
          <p>But in `7` minutes, the first tollbooth will have only serviced `7` cars. So there will be `3` cars still at the first tollbooth when the first car arrives at the second tollbooth.</p>
        </div>
        <button class="btn" type="button" data-bs-toggle="collapse" data-bs-target="#caravan_q2" aria-expanded="false" aria-controls="caravan_q2">Answer</button>
      </div>
      <h3>Queuing Delay and Packet Loss</h3>
      <p>Queuing delay is the most complicated delay since it varies from packet to packet (as implied, processing delay, transmission delay, and propagation delay are the same for every packet). For example, if 10 packets arrive at an empty queue, the first packet will have no queuing delay, but the last packet will have to wait for the first 9 packets to leave the queue.</p>
      <p>The factors that determine queuing delay are the rate at which traffic arrives, the transmission rate of the link, and the type of traffic that arrives (e.g., periodically or in bursts).</p>
      <div class="ln-box">
        <p>Let `a` be the average rate (in packets per second) at which packets arrive. If a packet has `L` bits, then `La` is the average rate (in bits per second) at which bits arrive. `R` is the transmission rate of the link. So `(La)/R` is the ratio of bits coming in vs bits going out; this ratio is called <b>traffic intensity</b>.</p>
        <p>`(La)/R gt 1` means that bits are arriving at the queue faster than they are leaving. In this case, the queuing delay will approach infinity.</p>
        <p>If `(La)/R le 1`, then the type of traffic that arrives has an effect on the queuing delay. For example, if one packet arrives every `L/R` seconds, then the packet will always arrive at an empty queue, so there will be no queuing delay.</p>
        <p>However, if `N` packets arrive in bursts every `NL/R` seconds, then the first packet will experience no queuing delay. But the second packet will experience a queuing delay of `L/R` seconds. The third packet will experience a queuing delay of `2L/R` seconds. Generally, each packet will have a queuing delay of `(n-1)L/R` seconds.</p>
      </div>
      <div class="ln-box">
        <p>Average queuing delay grows exponentially with traffic intensity, i.e., a small increase in traffic intensity results in a large increase in average queuing delay.</p>
      </div>
      <h4>Packet Loss</h4>
      <p>If packets are coming in faster than they are leaving the queue, then the queue will eventually be full and not be able to store any more packets. In this case, some packets will be <b>dropped</b> or <b>lost</b>. As traffic intensity increases, so does the size of the queue, which means the number of packets lost also increases.</p>
      <h3>End-to-End Delay</h3>
      <p>End-to-end delay is the total delay that a packet experiences from source to destination.</p>
      <div class="ln-box">
        <p>Suppose there are `N-1` routers between the source and destination. Then there are `N` links. Also suppose that the network is uncongested so there are practically no queuing delays.</p>
        <p>Then the end-to-end delay is `d_text(end-end)=Nd_text(proc)+Nd_text(trans)+Nd_text(prop)=N(d_text(proc)+d_text(trans)+d_text(prop))`.</p>
      </div>
      <h4>Traceroute</h4>
      <p>Traceroute is a program that allows us to see how packets move and how long they take. We specify the destination we want to send some packets to and the program will print out a list of all the routers the packets went through and how long it took to reach that router.</p>
      <div class="ln-box">
        <p>Suppose there are `N-1` routers between the source and destination. Traceroute will send `N` special packets into the network, one for each router and one for the destination. When the nth router receives the nth packet, it sends a message back to the source. When it receives a message, the source records the time it took to receive the message and where the message came from. Traceroute performs these steps 3 times.</p>
      </div>
      <h3>Throughput</h3>
      <p>Throughput is the rate at which bits are transferred between the source and destination. The <b>instantaneous throughput</b> is the rate at any point during the transfer. The <b>average throughput</b> is the rate over a period of time.</p>
      <div class="ln-box">
        <p>If a file has `F` bits and the transfer takes `T` seconds, then the average throughput of the file transfer is `F/T` bits per second.</p>
      </div>
      <p>Suppose we have two end systems connected by two links and one router. Let `R_s`, `R_c` be the rates of the two links.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/throughput.png">
      </div>
      <p>Suppose `F=32,000,000` bits, `R_s=2` Mbps, and `R_c=1` Mbps.</p>
      <ul>
        <li>After `1` second, `2,000,000` bits will move from the server to the router.</li>
        <li>After `2` seconds, `2,000,000` bits will move from the server to the router and `1,000,000` bits will move from the router to the client.</li>
        <li>After `3` seconds, `2,000,000` bits will move from the server to the router and `1,000,000` bits will move from the router to the client.</li>
        <li>After `4` seconds, `2,000,000` bits will move from the server to the router and `1,000,000` bits will move from the router to the client.</li>
      </ul>
      <p>The file transfer is complete when the client receives `32,000,000` bits, which means `1,000,000` bits will have to move from the router to the client `32` times. Since it takes `1` second to do so, it will take `32` seconds for the file transfer to complete.</p>
      <p>Notice how it didn't matter how fast the bits moved from the server to the router. The time the file took to reach the client only depended on the rate from the router to the client. This doesn't mean the time it takes to reach the client is always equal to the rate from router to client though. Let's flip the numbers around to prove this point.</p>
      <p>Suppose `F=32,000,000` bits, `R_s=1` Mbps, and `R_c=2` Mbps.</p>
      <ul>
        <li>After `1` second, `1,000,000` bits will move from the server to the router.</li>
        <li>After `2` seconds, `1,000,000` bits will move from the server to the router and `1,000,000` bits will move from the router to the client.</li>
        <li>After `3` seconds, `1,000,000` bits will move from the server to the router and `1,000,000` bits will move from the router to the client.</li>
        <li>After `4` seconds, `1,000,000` bits will move from the server to the router and `1,000,000` bits will move from the router to the client.</li>
      </ul>
      <p>Wait, but isn't the rate from router to client `2,000,000` bits per second? Why aren't `2,000,000` bits moving from router to client every second? That's because there are only `1,000,000` bits entering the router every second.</p>
      <p>From this, we can see that the throughput of a file transfer depends on the link that is transferring bits at the lowest rate. This link is called the <b>bottleneck link</b>.</p>
      <div class="ln-box">
        <p>Mathematically, the throughput is `min(R_s,R_c)`.</p>
        <p>The time it takes to transfer the file is `F/(min(R_s,R_c))`.</p>
      </div>
      <div class="ln-box">
        <p>Generally, the throughput for a network with `N` links is `min(R_1,R_2,...,R_n)`.</p>
      </div>
      <p>The bottleneck link is not always the link with the lowest transmission rate. We'll look at another example to show this.</p>
      <p>Suppose there are `10` clients downloading data from `10` servers (each client is connected to a unique server). Suppose they all share a common link with transmission rate `R` somewhere in the network core. We'll denote the transmission rates of the server links as `R_s` and the transmission rates of the client links as `R_c`.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/throughput_2.png">
        <p>(I think sharing a common link means all the server links eventually connect to one router and all the client links eventually connect to a different router. And the link between these two routers are the same.)</p>
      </div>
      <p>Let's assign actual values to these transmission rates. So let `R_s=2` Mbps, `R_c=1` Mbps, and `R=5` Mbps. Since the common link is being used for `10` simultaneous downloads, the link divides its transmission rate equally among the `10` connections. So now the common link is transferring bits at a rate of `(5text(Mbps))/10=500` kbps. Which means the throughput for each download is `500` kbps. Even though the common link had the highest transmission rate, it ended up being the bottleneck link.</p>
      <div class="ln-box">
        <p>Links in the network core are almost never the bottleneck link because they are usually over-provisioned with high speed links. Typically, the bottleneck links are in the access network.</p>
      </div>
      <h2 id="protocollayers">Protocol Layers</h2>
      <p>There are many pieces to the Internet, like routers, links, applications ("apps"), protocols, and end systems. These pieces are organized into layers.</p>
      <h3>Layered Architecture: The Internet Is Like an Onion</h3>
      <p>The airline system can be seen as an organization of layers.</p>
      <table class="table">
        <tr>
          <th>Layer</th>
          <th>Action (Leaving)</th>
          <th>Action (Arriving)</th>
        </tr>
        <tr>
          <td>Ticketing</td>
          <td>Purchase</td>
          <td>Complain</td>
        </tr>
        <tr>
          <td>Baggage</td>
          <td>Check</td>
          <td>Claim</td>
        </tr>
        <tr>
          <td>Gates</td>
          <td>Enter</td>
          <td>Exit</td>
        </tr>
        <tr>
          <td>Runway</td>
          <td>Takeoff</td>
          <td>Land</td>
        </tr>
        <tr>
          <td>Airplane</td>
          <td>Routing</td>
          <td>Routing</td>
        </tr>
      </table>
      <p>Every time we board and leave an airplane, we perform the same steps in a certain order. And the action we perform depends on the layer we're at since each layer is responsible for one thing and one thing only. (I.e., Each layer provides a different service.) Also, each layer depends on the layer before it. For example, we can only check in our baggage if we have a ticket, or we can only enter the gate once we have checked in our baggage.</p>
      <p>This layering makes it easier to distinguish the different components of an airline system. It also makes it easier to change the implementation of a layer's service without affecting the rest of the layers. For example, the current implementation of the gate layer is to board people by ticket priority and check-in time. But the implementation can be changed to board people by height. This change doesn't affect any of the other layers, and the function of this layer remains the same: getting people on the airplane.</p>
      <h4>Protocol Layering</h4>
      <p>The Internet is made up of 5 layers.</p>
      <table class="table">
        <tr>
          <th>Layer</th>
        </tr>
        <tr>
          <td>5. Application</td>
        </tr>
        <tr>
          <td>4. Transport</td>
        </tr>
        <tr>
          <td>3. Network</td>
        </tr>
        <tr>
          <td>2. Link</td>
        </tr>
        <tr>
          <td>1. Physical</td>
        </tr>
      </table>
      <p>Recall that a protocol is a set of rules that define how things should work. Each protocol belongs to one of the layers.</p>
      <h4>Application Layer</h4>
      <p>The application layer includes all the network applications (basically apps or programs that connect to the Internet).</p>
      <table class="table">
        <tr>
          <th>Protocol</th>
          <th>Details</th>
        </tr>
        <tr>
          <td>HTTP</td>
          <td>sending and receiving Web documents</td>
        </tr>
        <tr>
          <td>SMTP</td>
          <td>sending and receiving emails</td>
        </tr>
        <tr>
          <td>FTP</td>
          <td>sending and receiving files</td>
        </tr>
      </table>
      <p>Applications communicate with each other by sending <b>messages</b> to each other.</p>
      <h4>Transport Layer</h4>
      <p>The transport layer is responsible for delivering the application's message to the network core.</p>
      <table class="table">
        <tr>
          <th>Protocol</th>
          <th>Details</th>
        </tr>
        <tr>
          <td>TCP</td>
          <td>
            <p>connection oriented</p>
            <p>guaranteed delivery</p>
          </td>
        </tr>
        <tr>
          <td>UDP</td>
          <td>
            <p>connectionless</p>
            <p>no reliability, no flow control, no congestion control</p>
          </td>
        </tr>
      </table>
      <p>In the transport layer, the packets of information are called <b>segments</b>.</p>
      <h4>Network Layer</h4>
      <p>The network layer is responsible for moving the transport layer's segments from router to router.</p>
      <table class="table">
        <tr>
          <th>Protocol</th>
          <th>Details</th>
        </tr>
        <tr>
          <td>IP</td>
          <td>
            <p>defines how packets must be formatted</p>
            <p>defines the actions that must be taken when sending or receiving packets</p>
          </td>
        </tr>
      </table>
      <p>In the network layer, the packets are called <b>datagrams</b>.</p>
      <h4>Link Layer</h4>
      <p>The link layer is responsible for moving the network layer's datagrams across links.</p>
      <table class="table">
        <tr>
          <th>Protocol</th>
        </tr>
        <tr>
          <td>Ethernet</td>
        </tr>
        <tr>
          <td>WiFi</td>
        </tr>
        <tr>
          <td>DOCSIS</td>
        </tr>
      </table>
      <p>In the link layer, the packets are called <b>frames</b>.</p>
      <h4>Physical Layer</h4>
      <p>The physical layer is responsible for moving the individual bits of the link layer's frames across links.</p>
      <div class="ln-box">
        <h4>OSI Model</h4>
        <p>In the late 1970s (before the Internet became public), there was another model that was proposed by the International Organization for Standardization (ISO) on how to organize computer networks. This model was called the Open Systems Interconnection (OSI) model and it had 7 layers:</p>
        <table class="table">
        <tr>
          <th>Layer</th>
        </tr>
        <tr>
          <td>7. Application</td>
        </tr>
        <tr>
          <td>6. Presentation</td>
        </tr>
        <tr>
          <td>5. Session</td>
        </tr>
        <tr>
          <td>4. Transport</td>
        </tr>
        <tr>
          <td>3. Network</td>
        </tr>
        <tr>
          <td>2. Link</td>
        </tr>
        <tr>
          <td>1. Physical</td>
        </tr>
      </table>
      <p>The layers that also appear in the Internet model work roughly the same way. So we'll just go over the ones that are new.</p>
      <p>The presentation layer makes sure the data is readable and usable. It provides data compression, data encryption, and data description. I guess it's sorta like a translator.</p>
      <p>The session layer makes sure the data goes where it needs to go. It provides data synchronization, checkpointing, and data recovery.</p>
      </div>
      <h3>Encapsulation</h3>
      <p>Whenever we moved across the different layers, we called the packets of information by a different name. That is because the packets change as they move from layer to layer.</p>
      <ol>
        <li>Application layer sends message</li>
        <li>Transport layer adds transport-layer header information to the message, forming a segment</li>
        <li>Network layer adds network-layer header information to the segment, forming a datagram</li>
        <li>Link layer adds link-layer header information to the datagram, forming a frame</li>
      </ol>
      <p>The header information is needed so that the thing (e.g., router, link, end system) receiving the packet knows what it is and what to do with it. Here are some animations to illustrate:</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/encapsulation.gif">
      </div>
      <p>End systems implement all 5 layers while routers usually implement only the bottom 3 layers (network, link, physical).</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/encapsulation_2.gif">
      </div>
      <p>Notice that when the packet left the end system, the last header added was the link-layer header, which is the first thing that gets processed when entering the router. When the packet reaches the link layer, the link-layer headers are extracted away. So now the top-most header is the network-layer header, which is what the network layer then processes.</p>
      <p>After going through the network layer, the router determines that the packet has to go on another link again. So now the packet has to travel down the layers. When it goes from the network layer down to the link layer, a new link-layer header is added, so that the next thing (router or end system) can process it.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-small" src="../pictures/networking/encapsulation_3.gif">
      </div>
      <p>Now that the packet has reached the end system, it goes up the layers one last time. Again, at each layer the headers are removed until only the message remains, which the application understands.</p>
      <hr>
      <p>From this point on, we'll go into more detail for each layer, starting with the application layer.</p>
      <hr>
      <h2 id="networkapplications">Principles of Network Applications</h2>
      <p>A network application is a set of apps or programs that connect to and communicate with the Internet. These apps are made by our local software developers using languages like C, Java, or Python.</p>
      <p>Typically, network applications involve multiple programs running on different end systems. For example, we can download Spotify on our phone, tablet, computer, or watch. And Spotify will have a different program running on their servers to provide functionality to the app.</p>
      <h3>Network Application Architectures</h3>
      <p>There are 2 types of network application architectures: client-server and peer-to-peer (P2P).</p>
      <p>In the client-server architecture, there is a server that is always on and running. Whenever clients want data, they make a request to the server, which then provides the clients with what they requested. In addition to always being on, the server has a fixed IP address, so clients can make requests to the server at any time.</p>
      <p>Big companies, like Google, need more than one server to handle all the requests, otherwise that one server would get overwhelmed. So they set up <b>data centers</b>, which house multiple servers. And then they go and set up multiple data centers.</p>
      <p>In peer-to-peer architecture, there are no servers (and thus no clients). Instead, devices communicate directly with other devices — called peers — to transfer data.</p>
      <p>Let's say you wanted to download a large file (perhaps an online textbook 🤫). You could go online and download it (this would be client-server), but let's say the file is so large, that it takes too long. Suppose that I happen to have the complete file already downloaded. Using the right application, I could transfer my file directly to your computer. Suppose that someone else also has the file. Then you can receive the file from both of us. And the more people that have the file, the more people you can connect to to receive the file, making the download faster.</p>
      <p>The effectiveness of peer-to-peer relies on the number of peers. The more peers there are, the more computing power there is. This is referred to as <b>self-scalability</b>.</p>
      <h3>Processes Communicating</h3>
      <p>We call them programs. Operating systems call them <b>processes</b>.</p>
      <h4>Client and Server Processes</h4>
      <p>A network application consists of pairs of processes that send messages to each other. A Web broswer (a process) communicates with a Web server (another process). Spotify, the app (a process), communicates with Spotify's servers (another set of processes). The process that is requesting data is the <b>client</b> process and the process that is providing the data is the <b>server</b> process. Despite the naming, the terms "client" and "server" processes apply for both client-server architecture and peer-to-peer architecture.</p>
      <div class="ln-box">
        <p>More formally (and perhaps more accurately), client processes are the ones that initiate communication and server processes are the ones that wait to be contacted.</p>
      </div>
      <h4>The Interface Between the Process and the Computer Network</h4>
      <p>As we saw before, a process in the application layer sends a message to the transport layer. In order to do so, it opens a <b>socket</b>, which is the application layer's door to the transport layer. Sockets are also used to receive messages from the transport layer.</p>
      <div class="ln-box">
        <p>For us developers, sockets are also referred to as the <b>Application Programming Interface</b> (<b>API</b>) between the application and the network. We don't have control over how the socket is implemented; that's handled by the OS.</p>
      </div>
      <h4>Addressing Processes</h4>
      <p>In order for the message to go to the correct place, the sending process needs to specify where the message needs to be delivered to. First, it needs to specify which end system is receiving the message. Each end system has a unique identifier called an <b>IP address</b>. Knowing just the end system is not enough though because an end system is running multiple applications while it's on, and we need to know which application needs the message. Whenever processes open a socket, they must choose a number to "label" the socket. This number is called a <b>port number</b>.</p>
      <h3>Transport Services Available to Applications</h3>
      <p>On the other side of the socket is a transport-layer protocol that delivers the message to the socket of the receiving process. There are several transport-layer protocols an application can choose from.</p>
      <h4>Reliable Data Transfer</h4>
      <p>As we saw earlier, packets can get lost. For some situations, like transferring financial documents, packet loss is undesirable. But even though packets can get lost, a protocol can still guarantee that the file will be delivered correctly. Then that protocol provides <b>reliable data transfer</b>.</p>
      <p>In other situations, like video calls, some packet loss is acceptable. ("I'm sorry, can you repeat that? You cut out for a few seconds.") Those applications are referred to as <b>loss-tolerant applications</b>.</p>
      <h4>Throughput</h4>
      <p>Throughput is the rate at which bits are transferred between the source and destination (I feel like I've said these exact words before). A transport-layer protocol can guarantee a specified throughput of some amount of bits per second. This would be useful for voice calls, which need a certain throughput in order for the voices to be heard clearly. Applications that have throughput requirements are <b>bandwidth-sensitive applications</b>.</p>
      <p>Applications that don't are <b>elastic applications</b>. File transfers don't need a certain throughput. If more bits can be transferred, then the download will be faster. If fewer bits can be transferred, then the download will be slower.</p>
      <h4>Timing</h4>
      <p>Whereas throughput is the number of bits going through, timing is the delay between each bit. One timing guarantee might be that bits go to the receiving process every 100 milliseconds. For real-time applications, like video calls and online games, it is ideal to have low delay.</p>
      <h4>Security</h4>
      <p>Before transferring the data, a transport protocol can encrypt it.</p>
      <h3>Transport Services Provided by the Internet</h3>
      <p>There are 2 transport protocols an application can use: TCP and UDP.</p>
      <h4>TCP</h4>
      <p>TCP is a connection-oriented protocol. The client and server have to confirm a connection (<b>TCP connection</b>) with each other first before messages can be transferred. And once the application is done sending messages, it must close the connection.</p>
      <p>TCP also provides reliable data transfer. This means data is sent without error and in the proper order — there are no missing or duplicate bytes. Part of this is achieved by implementing congestion control. If the network is congested, the sending process will be throttled.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-smaller" src="../pictures/networking/tcp_comic.png">
      </div>
      <h4>UDP</h4>
      <p>UDP is like the opposite of TCP. It's connectionless. The data transfer is unreliable — there's no guarantee all the messages will arrive and if it does arrive, there's no guarantee that the messages will arrive in order. And there's no congestion control. All of these things sound bad, so why does UDP even exist in the first place?</p>
      <p>Well no congestion control means that UDP can send bits at any rate with no limits*. This is good for voice call applications because they want data to be sent as much as possible and as fast as possible.</p>
      <p>*However, there will be actual limitations to this rate, including link transmission rate and network congestion.</p>
      <div class="ln-box">
        <p>For some reason, most firewalls are configured to block most types of UDP traffic. So applications that use UDP have to be prepared to use TCP as a backup.</p>
      </div>
      <div class="ln-box">
        <table class="table">
          <tr>
            <th>Application</th>
            <th>Application-Layer Protocol</th>
            <th>Transport-Layer Protocol</th>
          </tr>
          <tr>
            <td>Email</td>
            <td>SMTP</td>
            <td>TCP</td>
          </tr>
          <tr>
            <td>Remote terminal access</td>
            <td>SSH</td>
            <td>TCP</td>
          </tr>
          <tr>
            <td>Web</td>
            <td>HTTP</td>
            <td>TCP</td>
          </tr>
          <tr>
            <td>File transfer</td>
            <td>FTP</td>
            <td>TCP</td>
          </tr>
          <tr>
            <td>Streaming</td>
            <td>HTTP</td>
            <td>TCP</td>
          </tr>
          <tr>
            <td>Internet telephony</td>
            <td>SIP, RTP, etc.</td>
            <td>TCP or UDP</td>
          </tr>
        </table>
      </div>
      <div class="ln-box">
        <p>TCP and UDP both <em>don't</em> guarantee:</p>
        <ul>
          <li>throughput</li>
          <li>timing</li>
          <li>security*</li>
        </ul>
        <p>Despite this, time-sensitive applications still work. This is because they are designed with these lack of guarantees in mind.</p>
        <p>*TCP can be enchanced with <b>Transport Layer Security</b> (<b>TLS</b>) to provide encryption. TLS is not a protocol; it's an add-on to TCP.</p>
      </div>
      <h3>Application-Layer Protocols</h3>
      <p>Application-layer protocols define:</p>
      <ul>
        <li>the types of messages exchanged (e.g., request and response messages)</li>
        <li>the format of the messages
          <ul>
            <li>what fields can go in a message</li>
          </ul>
        </li>
        <li>the meaning of the information in the fields</li>
        <li>rules for determining when and how processes send and respond to messages</li>
      </ul>
      <p>Some protocols are defined in RFCs and are therefore public. While other protocols, like Skype's, are proprietary.</p>
      <h2 id="http">The Web and HTTP</h2>
      <p>The Internet became big in the 1990s with the arrival of the World Wide Web.</p>
      <h3>Some Dry Facts About HTTP</h3>
      <p>A <b>Web page</b> is a document with a bunch of <b>objects</b>, which can be images, videos, JavaScript files, CSS style sheets, etc. (More formally, an object is a file that is addressable by a single URL.) A Web page is usually an HTML file that includes references to these objects. <b>Web browsers</b> request and display Web objects while <b>Web servers</b> store Web objects.</p>
      <p>HTTP stands for <b>HyperText Transfer Protocol</b>, and it is the Web's application-layer protocol. When browsers request a Web page, they send HTTP request messages to the server and the server responds with HTTP response messages that contain the objects.</p>
      <p>HTTP uses TCP as its transport protocol. Port 80 is reserved for HTTP, so when browsers and servers initialize their sockets, they use port 80.</p>
      <p>HTTP is a <b>stateless protocol</b>. This means that the server does not store any information about the exchanges the server has with clients. For example, the server will not know if a particular client has asked for a Web page before or if it's the client's first time asking for the Web page.</p>
      <div class="ln-box">
        <p>The original version of HTTP is called HTTP/1.0. Then there was HTTP/1.1 (1997), HTTP/2 (2015), and HTTP/3 (2022).</p>
      </div>
      <h3>Non-Persistent and Persistent Connections</h3>
      <p>Each time a browser makes a request for a Web page, the browser actually has to make a request for the base HTML file and then each object in the file. In <b>non-persistent connections</b>, the browser opens a TCP connection for each object. In <b>persistent connections</b>, the browser opens one TCP connection and requests/receives all the objects using that one connection. HTTP uses persistent connections by default.</p>
      <h4>HTTP with Non-Persistent Connections</h4>
      <ol>
        <li>Browser starts a TCP connection to the server on port 80</li>
        <li>Browser sends an HTTP request message to the server</li>
        <li>Server receives the request, gets the base file, puts it in an HTTP response message, and sends the message</li>
        <li>Server closes the TCP connection</li>
        <li>Browser receives the response.</li>
      </ol>
      <p>And these steps repeat for each object in the Web page. So if a Web page has `10` objects, there will be `11` connections made (`1` for the Web page and `10` for each object). While this may seem tedious, browsers can be configured to open multiple parallel connections at the same time instead of waiting for one connection to be done before opening another.</p>
      <p>Let's look at one request in action:</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-smaller" src="../pictures/networking/http.gif">
      </div>
      <p>As we can see, it takes some time for the client to receive the file after making a request.</p>
      <p>The <b>round-trip time</b> (<b>RTT</b>) is the time it takes for a packet to travel from client to server. The delays we saw in the "Delay, Loss, and Throughput" section also factor into the RTT.</p>
      <div class="ln-center">
        <img class="img-fluid ln-image-smaller" src="../pictures/networking/rtt.png">
      </div>
      <p>So the total response time is `2` RTTs plus the transmission time of the file. `1` RTT is for establishing the TCP connection and `1` RTT is for sending the file.</p>
      <p>Besides the delay for sending each object, there is also the burden of resource management. For each TCP connection, buffers and variables must be allocated; this can take up a lot of resources on the server if there are a bunch of clients.</p>
      <h4>HTTP with Persistent Connections</h4>
      <p>Instead of closing the TCP connection after sending the requested object, the server keeps the connection open for a certain period of time.</p>
      <div class="ln-box">
        <p>For both non-persistent and persistent connections, they can also be non-parallel or parallel. In non-parallel connections, the client waits until it receives an object before requesting another one. So each object requires `1` RTT. In parallel connections, the client requests an object as soon as it needs it, even if a previous request for an object has not been completed yet. This means if there are `n` objects, it could request for all `n` objects at once. So it could take as little as `1` RTT to get all the objects. (Note that the `1` RTT is just for the objects in the base file. The browser needs `1` RTT to get the base file itself first.)</p>
      </div>
      <div class="ln-box">
        <p>Suppose there is a `100`-kilobit page that contains `5` `100`-kilobit images, all of which are stored on a server. Suppose the round-trip time from the server to a client's browser is `200` milliseconds. For simplicity, we'll assume there is only one `100` Mbps link between the client and server; the time it takes to transmit a GET request onto the link is zero; and it takes some time to transmit things onto the link (well this last one technically doesn't need to be assumed). Note that based on the assumptions, the link has a `100` millisecond one-way propagation delay as well as a transmission delay.</p>
        <p>For non-persistent, non-parallel connections, how long is the response time? (The time from when the user requests the URL to the time when the page and its images are displayed?)</p>
        <div class="collapse ln-box" id="http_q1">
          <p>Let's start with the base file. It takes `1` RTT to establish the TCP connection and another `1` RTT to get the base file. So it takes a total of `2` RTTs for the base file. We are given that one RTT is `200` milliseconds, so it takes `200*2=400` milliseconds for the base file to propagate through the link.</p>
          <p>The transmission delay for the base file is `L/R=(100text( kb))/(100text( Mbps))=(100,000text( bits))/(100,000,000text( bits/s))=0.001` seconds `=1` millisecond.</p>
          <p>So the total time it takes to get the base file is `400+1=401` milliseconds.</p>
          <p>Now for the objects. Since it is non-persistent, the TCP connection for the base file will be closed and new ones (`1` each) will be needed for the objects. Since it is non-parallel, the previous TCP connection has to close before a new one opens.</p>
          <p>For one object, it takes `1` RTT to establish the TCP connection, and `1` RTT to get the object. So `2` RTTs for one object. For `5` objects, this is a total of `5*2=10` RTTs. In terms of milliseconds, this is `200*10=2000` milliseconds.</p>
          <p>The transmission delay for one object is the same for the base file. Then for `5` objects, the transmission delay is `1*5=5` milliseconds.</p>
          <p>So the total time it takes to get all of the objects is `2000+5=2005` milliseconds.</p>
          <p>Bringing the total time for the whole Web page to `2005+401=2406` milliseconds `=2.406` seconds.</p>
        </div>
        <button class="btn" type="button" data-bs-toggle="collapse" data-bs-target="#http_q1" aria-expanded="false" aria-controls="http_q1">Answer</button>
        <p>What about for non-persistent, parallel connections?</p>
        <div class="collapse ln-box" id="http_q2">
          <p>Again, we'll start with the base file. It takes `1` RTT to establish the TCP connection and another `1` RTT to get the base file. So `2` RTTs. Same as before, `2*200=400` milliseconds for the base file to propagate.</p>
          <p>The transmission delay is also the same at `1` millisecond.</p>
          <p>So the total time it takes to get the base file is `400+1=401` milliseconds.</p>
          <p>For the objects, since the connections are parallel, all `5` objects will be retrieved at the same time in `1` RTT. Also, all `5` TCP connections will be opened parallelly in `1` RTT. So `2` RTTs for all `5` objects. This is also `2*200=400` milliseconds for them to propagate.</p>
          <p>Even though the connections are parallel, the objects are not transmitted onto the link parallelly. (There is only one link, so only one object can be transmitted at a time.) As we saw before, it takes `1` millisecond to transmit `1` object. So for `5` objects, `5` milliseconds.</p>
          <p>So the total time it takes to get all of the objects is `400+5=405` milliseconds.</p>
          <p>Bringing the total time for the whole Web page to `401+405=806` milliseconds `=0.806` seconds.</p>
        </div>
        <button class="btn" type="button" data-bs-toggle="collapse" data-bs-target="#http_q2" aria-expanded="false" aria-controls="http_q2">Answer</button>
        <p>What about for persistent, non-parallel connections?</p>
        <div class="collapse ln-box" id="http_q3">
          <p>We open the TCP connection and wait for the base file to transmit and propagate, which takes `401` milliseconds.</p>
          <p>For the objects, since the connection is persistent, we don't need to open any more TCP connections.</p>
          <p>But since it is non-parallel, we need to get the objects one at a time. `1` RTT for each object means `5` RTTs for all objects, which means `5*200=1000` milliseconds for all objects to propagate.</p>
          <p>And `5` milliseconds to transmit.</p>
          <p>So the total time it takes to get all of the objects is `1000+5=1005` milliseconds.</p>
          <p>Bringing the total time for the whole Web page to `401+1005=1406` milliseconds `=1.406` seconds.</p>
        </div>
        <button class="btn" type="button" data-bs-toggle="collapse" data-bs-target="#http_q3" aria-expanded="false" aria-controls="http_q3">Answer</button>
        <p>What about for persistent, parallel connections?</p>
        <div class="collapse ln-box" id="http_q4">
          <p>The base file takes `401` milliseconds to transmit and propagate.</p>
          <p>We don't need to open any more TCP connections, and all `5` objects will be retrieved at once in `1` RTT. So `200` milliseconds to propagate.</p>
          <p>`5` milliseconds to transmit.</p>
          <p>So the total time it takes to get all of the objects is `200+5=205` milliseconds.</p>
          <p>Bringing the total time for the whole Web page to `401+205=606` milliseconds `=0.606` seconds.</p>
        </div>
        <button class="btn" type="button" data-bs-toggle="collapse" data-bs-target="#http_q4" aria-expanded="false" aria-controls="http_q4">Answer</button>
      </div>
      <h3>HTTP Message Format</h3>
      <p>There are two types of HTTP messages: request messages and response messages.</p>
      <h4>Request Messages: Give Me What I Want!</h4>
      <p>Here's an example of what a request message might look like:</p>
      <p><code>GET /projects/page.html HTTP/1.1<br>Host: www.myschool.edu<br>Connection: close<br>User-agent: Mozilla/5.0<br>Accept-language: fr</code></p>
      <p>The first line is the <b>request line</b>. There are three fields: the method field, the URL field, and the HTTP version field. As we can infer, the method is GET, which is the method for requesting objects (because, you know, we want to "get" it).</p>
      <p>The lines below the request line are the <b>header lines</b>. <code>Connection: close</code> means "close the connection after giving me what I requested", i.e., use a non-persistent connection. <code>Connection: keep-alive</code> is for a persistent connection. The user agent specifies what type of browser is making the request. And <code>Accept-language: fr</code> means get the French version if it exists.</p>
      <div class="ln-box">
        <p>It may look like the header line specifying the host is unnecessary, because the browser needed to know the host in order to establish the TCP connection in the first place. It turns out that it is needed by Web proxy caches, which we'll see later.</p>
      </div>
      <p>There is also an entity body that follows the header lines. It wasn't included in the example above because the entity body is usually empty for GET requests. The entity body is usually used for POST requests, which are used to submit information, like user inputs from a form. The information that needs to be submitted are included in the entity body.</p>
      <div class="ln-box">
        <p>This is a little bit unconventional, but GET requests can also be used to submit information. Instead of going in the entity body, the inputted data is included in the URL with a question mark, like google.com/search?q=what+is+http, where q is the name of the input and the stuff after the '=' is the value of the input.</p>
      </div>
      <h4>Response Messages: Here You Go, Now Leave Me Alone!</h4>
      <p>Here's an example of what a response message might look like:</p>
      <p><code>HTTP/1.1 200 OK<br>Connection: close<br>Date: Sat, 16 Sep 2023 19:23:09 GMT<br>Server: Apache/2.2.3 (CentOS)<br>Last-Modified: Sat, 16 Sep 2023 18:34:09 GMT<br>Content-Length: 6821<br>Content-Type: text/html<br><br>(the requested data...)</code></p>
      <p>The first line is the <b>status line</b>. There are three fields: the protocol version, the status code, and the status message.</p>
      <p>The lines below are the <b>header lines</b>. The <code>Date:</code> header line specifies when the HTTP response was created and sent by the server. The <code>Server:</code> header line specifies the type of the Web server. <code>Last-Modified:</code> is when the object was created or last modified. <code>Content-Length:</code> specifies the object's size in bytes.</p>
      <p>The <b>entity body</b> contains the actual object.</p>
      <h3>Cookies! 🍪</h3>
      <p>HTTP is stateless, so the server doesn't store information about the requests that the clients are making. However, servers sometimes want a way to identify users so that they can restrict access or provide user-specific information when responding to the client. This is where cookies come in. Cookies allow sites to keep track of users.</p>
      <p>Let's say we go to our favorite shopping site on our favorite browser. The site creates a unique ID (let's say 9876) for this request, stores the ID in its database, and sends the ID back in the response. The response includes a <code>Set-cookie:</code> header; this tells the browser to create and store a cookie file. For example, the header will look like <code>Set-cookie: 9876</code>, so the browser will store 9876 in a file. Now, as we navigate through our shopping site, the site can ask the browser to include this cookie in every request. Then the site will query the database for this ID to identify the user. If the ID exists in the database, the site will know the user has visited before, and if the ID doesn't in the database, the site will consider this a new user visiting for the first time.</p>
      <p>When we say that the site can identify the user, the site doesn't actually know who we are, like our name and stuff. Until we enter that information ourselves. When we enter our information to buy something or to fill out a form, the site can store that information and associate that with the ID in the cookie. So the next time we visit that site, it can look at the ID and the information linked to that ID.</p>
    </div>
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-HwwvtgBNo3bZJJLYd8oVXjrBZt8cqVSpeBNS5n7C8IVInixGAoxmnlMuBnhbgrkm" crossorigin="anonymous"></script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
  </body>
</html>
